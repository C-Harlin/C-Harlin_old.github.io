<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>理解VAE</title>
      <link href="/2019/09/10/VAE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>/2019/09/10/VAE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<p>对VAE的理解一直都很模糊。由于打算用GAN来做实验，作为基础，有必要彻底把VAE弄懂。 回过头又把CS231n关于VAE的部分来回看了好几遍，说真的，Serena Yeung讲得比Justin小哥差太多了，实在没法理解。 所幸在网上找到了一篇<a href="https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf" target="_blank" rel="noopener">博文</a>，清晰明了。 博文里已经讲得很清楚了，我在此用自己的理解做一总结。 <a id="more"></a></p><h2 id="动机">动机</h2><p>自编码器的缺点在于，不同类别的样本映射到特征空间后是不连续的。</p><p><img src="https://raw.githubusercontent.com/C-Harlin/MarkDownPhotos/master/vae/AE_embed.png" width="50%" height="50%"> 例如上图是在MNIST数据集上训练得到，可以看到不同类别的数字图像在二维空间中被明显地分开。它的好处仅表现在取区分和训练数据相似的数据。</p><p>但生成模型的目的是从潜在空间（latent space）中随机采样，或是在输入图像的基础上生成一些变体（要求潜在空间的连续性），从上图明显可以看出，潜在空间中还有大量没有被覆盖到的区域——如果在这些区域上采样，解码器该如何判断？ 我们希望不同的类别彼此尽可能靠近同时又能区分开。 这就是VAE做的事情。</p><h2 id="概率解释">概率解释</h2><p>关于VAE我最大的疑惑就是encoder network的输出到底是什么。看到下面这张图后才豁然开朗。</p><p><img src="https://raw.githubusercontent.com/C-Harlin/MarkDownPhotos/master/vae/vae.png" width="50%" height="50%"></p><p>encoder network的输出的确是均值和方差，多维决定了这是多个随机变量，这才有了后面的多维高斯分布。 比如下图中均值和方差分别是30维，即30个随机变量，每组均值和方差都决定了一个高斯分布。从这些分布中采样即可得到<span class="math inline">\(z\)</span></p><p><img src="https://raw.githubusercontent.com/C-Harlin/MarkDownPhotos/master/vae/vae_gaussian.png" width="50%" height="50%"> 从分布中采样的好处是，即使对于同一个输入<span class="math inline">\(x\)</span>，encoder输出的<span class="math inline">\(z\)</span>也可能不同。因为这是按概率在均值<span class="math inline">\(\mu\)</span>和方差<span class="math inline">\(\sigma\)</span>确定的一片区域内采样得到的。其意义是使decoder将潜在空间的这片区域对应到同一个类别，而不再是只将潜在空间的一个点对应某一类别。</p><p><img src="https://raw.githubusercontent.com/C-Harlin/MarkDownPhotos/master/vae/vae_1.png" width="50%" height="50%"></p><h2 id="损失函数">损失函数</h2><p>回到我们的目标——使不同类别的输入在潜在空间中既能<strong>彼此靠近</strong>又能<strong>互相区分</strong>。</p><p><img src="https://raw.githubusercontent.com/C-Harlin/MarkDownPhotos/master/vae/vae_2.png" width="50%" height="50%"> 靠近：在没有约束的情况下，为了便于分类，encoder输出的<span class="math inline">\(\mu\)</span>和<span class="math inline">\(\sigma\)</span>会很分散。其后果就是不同随机变量的分布在潜在空间中“各自为王”。VAE的做法是让这些随机变量的分布都向标准正态分布靠近，偏离则会受到惩罚，其本质就是正则化。度量分布之间的距离选用的是KL散度。</p><p>但仅仅考虑靠近在一起是下图这样的效果：</p><p><img src="https://raw.githubusercontent.com/C-Harlin/MarkDownPhotos/master/vae/vae_3.png" width="50%" height="50%"> 区分：靠decoder来完成。</p><p><img src="https://raw.githubusercontent.com/C-Harlin/MarkDownPhotos/master/vae/vae_4.png" width="50%" height="50%"> 最终的损失函数为：<span class="math display">\[ l_{i}(\theta, \phi)=-\mathbb{E}_{z \sim q_{\theta}\left(z | x_{i}\right)}\left[\log p_{\phi}\left(x_{i} | z\right)\right]+\mathbb{K} \mathbb{L}\left(q_{\theta}\left(z | x_{i}\right) \| p(z)\right) \]</span> 第一项就是decoder网络的优化目标，是为了将不同类别在局部上区分；第二项是正则项，为了在全局上保持连续性。</p><h2 id="生成过程">生成过程</h2><p>生成数据时只用到了decoder网络，即<span class="math inline">\(z\)</span>不再是从<span class="math inline">\(q_{\phi}(z | x)\)</span>中采样，而是直接从标准正态分布中采样。因为<span class="math inline">\(q_{\phi}(z | x)\)</span>只是为了训练decoder而引入的，目的是把样本数据集在潜在空间中聚拢，聚拢的目标是标准正态分布。经过训练后，decoder已经可以从这样的空间中区分不同类别的数据。生成时直接从标准正态分布采样<span class="math inline">\(z\)</span>即可。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>可学习理论</title>
      <link href="/2019/08/31/learning%20from%20data%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>/2019/08/31/learning%20from%20data%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<p>啊、 <a id="more"></a>​ ## 前三课</p><p>前三课主要讨论了是否可学习的问题，答案是肯定的：learning is feasible。 敢说出这个答案的底气来自Hoeffding不等式。</p><p><img src="https://raw.githubusercontent.com/C-Harlin/MarkDownPhotos/master/learning%20from%20data/lfd_2.png" width="80%" height="80%"></p><p>如果仅存在一种hypothesis，那么直接可以由Hoeffding不等式得到经验误差和真实误差之间差距的上界。</p><p>但现实中的模型并不存在只有一种假设的情况，假设的数量通常是无限。想要继续通过Hoeffding不等式来约束差距就会得到上图右半边的结果，即多了模型数量这一因子。</p><p>虽然这个上界很可能是没有意义的，但至少给出了一个上界，告诉我们是可以学习的。</p><p>关于为什么要引入这么多假设，教授用形象的例子给了解释。</p><p><img src="https://raw.githubusercontent.com/C-Harlin/MarkDownPhotos/master/learning%20from%20data/lfd_3.png" width="80%" height="80%"></p><p>对于同一问题，使用不同的假设<span class="math inline">\(h\)</span>（模型或不同参数的模型）会得到不同结果。这里的结果具体指样本内误差<span class="math inline">\(E_{in}(h)\)</span>和样本外误差<span class="math inline">\(E_{out}(h)\)</span>。其中一定存在一个假设<span class="math inline">\(g\)</span>使得在当前的所有假设中，<span class="math inline">\(g\)</span>的泛化能力最好，即<span class="math inline">\(E_{in}(h)\)</span>和<span class="math inline">\(E_{out}(h)\)</span>的差别最小。</p><p>所以，当你尝试一种假设并得到一组结果后，你肯定不敢相信这就是最终要寻找的那个假设——哪有那么幸运，只试了一次就找到。 所以你必然要尝试很多假设，然后从里面挑出结果最好的那个。 到这里就解释清楚为什么要引入多个模型。</p><p>但即使这样做了，你还是要问：凭什么相信“局部最优”的假设就是你想寻找的“全局最优”假设？ 你的怀疑是对的。 从数学上讲，在多种模型情况下的Hoeffding不等式给出的那个上界实在令人担忧。 当然这个问题留在之后解决。</p><p>下图是教授总结的有监督学习框架。</p><p><img src="https://raw.githubusercontent.com/C-Harlin/MarkDownPhotos/master/learning%20from%20data/lfd_1.png" width="80%" height="80%"></p><h2 id="第四课">第四课</h2><p>这一讲解释了数据噪声和学习过程的关系，引出了noisy target的概念。 由于现实中的数据不可能覆盖到所有特征，因此会出现特征相同的两个实例标签却不同的情况。 也正因为此，学习的目标不再是<span class="math inline">\(y=f(x)\)</span>（unknown target function），而是<span class="math inline">\(P(y|x)\)</span>（target distribution），即对于给定数据<span class="math inline">\(x\)</span>，有多大可能是<span class="math inline">\(y\)</span>。 下图是新的有监督学习框架。</p><p><img src="https://raw.githubusercontent.com/C-Harlin/MarkDownPhotos/master/learning%20from%20data/lfd_4.png" width="80%" height="80%"></p><p>目前我们已经知道了，学习是可行的，即：<span class="math display">\[ E_{in}(g)\approx E_{out}(g) \]</span> 但这还不够。我们期望的是<span class="math inline">\(g\approx f\)</span>，即：<span class="math display">\[ E_{out}(g)\approx 0 \]</span></p><h2 id="第五课">第五课</h2><p>从考虑了多种假设的Hoeffding不等式可以看出，这个概率上界过于保守，保守的原因是假设这<span class="math inline">\(M\)</span>个bad events之间没有重合。 所谓的bad event是指样本内误差和样本外误差超出<span class="math inline">\(\epsilon\)</span>：<span class="math display">\[ \left|E_{\mathrm{in}}\left(h_{m}\right)-E_{\mathrm{out}}\left(h_{m}\right)\right|&gt;\epsilon \]</span> 而联合上界为： <span class="math display">\[ \begin{aligned} \mathbb{P}\left[\mathcal{B}_{1} \text { or } \mathcal{B}_{2} \text { or } \cdots\right.&amp;\left.\text { or } \mathcal{B}_{M}\right] \\ &amp; \leq \underbrace{\mathbb{P}\left[\mathcal{B}_{1}\right]+\mathbb{P}\left[\mathcal{B}_{2}\right]+\cdots+\mathbb{P}\left[\mathcal{B}_{M}\right]}_{\text {no overlaps } M \text { terms }} \end{aligned} \]</span> 教授用一个例子解释了bad events之间的重合：</p><div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 100%;"><img src="https://raw.githubusercontent.com/C-Harlin/MarkDownPhotos/master/learning%20from%20data/lfd_7.png" alt="lfd_7"></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 100%;"><img src="https://raw.githubusercontent.com/C-Harlin/MarkDownPhotos/master/learning%20from%20data/lfd_7.png" alt="lfd_7"></div></div></div></div><p>图中的<span class="math inline">\(E_{out}\)</span>是指被误判的那部分在整个数据中所占的比例，而<span class="math inline">\(E_{in}\)</span>是指采样点中被误判的那部分占所的比例。 对于另一个假设（图中黄线所示），其与第一种假设的误差明显有重合的部分。 <img src="https://raw.githubusercontent.com/C-Harlin/MarkDownPhotos/master/learning%20from%20data/lfd_7.png%20=188x" alt="lfd_7"> 所以<span class="math inline">\(M\)</span>是有机会被替换掉的。 为了替换点<span class="math inline">\(M\)</span>，这里不再考虑整个输入空间，而是有限的输入点，计算这些点的dichotomies。又是一个形象的例子： <img src="https://raw.githubusercontent.com/C-Harlin/MarkDownPhotos/master/learning%20from%20data/lfd_8.png%20=488x" alt="lfd_8"> 左上角的红蓝区域代表着当前假设（那根直线）对输入空间的判别，但这是不可见的，因为无法获知整个输入空间。右上角图片可以想象成一张被打了若干个小孔的纸，叠在左上角图片上后可以透过小孔观察到小孔所属的颜色，即假设对采样点的判断。当选择不同假设时，这些采样点就会有不同的颜色。 <span class="math inline">\(dichotomy\)</span>的本意是“二分”，一些点会被判定为红色，另一些点会被判定为蓝色，这样的一个划分情况被称为一个<span class="math inline">\(dichotomy\)</span>。 <img src="https://raw.githubusercontent.com/C-Harlin/MarkDownPhotos/master/learning%20from%20data/lfd_9.png%20=488x" alt="lfd_9"> 上图很清楚地解释了相关概念。虽然<span class="math inline">\(|\mathcal{H}|\)</span>是无限的，但当无限的假设作用到有限的采样点上时，必然有很多假设会得到相同的结果，即<span class="math inline">\(dichotomy\)</span>的数量有限，最多为<span class="math inline">\(2^{N}\)</span>。</p><h3 id="growth-function">Growth function</h3><p>生长函数的作用是，给定数量<span class="math inline">\(N\)</span>，你来确定这<span class="math inline">\(N\)</span>个数据点应该放在哪些位置上，使得在当前的假设集合下，得到的<span class="math inline">\(dichotomy\)</span>数量最大，并返回这个最大值。它与假设集有关，也与数据量有关。 （dichotomy的数量肯定最多是<span class="math inline">\(2^N\)</span>，因为存在一些划分情况是假设集无法做到的） <img src="https://raw.githubusercontent.com/C-Harlin/MarkDownPhotos/master/learning%20from%20data/lfd_10.png%20=488x" alt="lfd_10"> 从无限到<span class="math inline">\(2^{N}\)</span>，虽然数值依然很大，但至少是一个改进。 通过下图这一简单的例子，可以更形象地理解生长函数。 <img src="https://raw.githubusercontent.com/C-Harlin/MarkDownPhotos/master/learning%20from%20data/lfd_11.png%20=488x" alt="lfd_11"> 中间的小图选择的点位只能使得dichotomy为6，但我们对此并不关心，因为生长函数要的是最大值。当<span class="math inline">\(N=4\)</span>时，数起来稍微麻烦了点，好在是能数出来。但如果<span class="math inline">\(N\)</span>的值更大了怎么办？</p><p>教授给出三个生长函数的实例，在这些例子中，目的都是使得dichotomy在当前假设集和数据量的前提下达到最大。 以第三个例子为例，任选k个点，在这k个点组成的convex多边形包围内的所有点都预测+1，否则预测-1。为了使得dichotomy最大，将N个数据点围成一个圈，则这N个点的任意一种排列组合都能成为一个dichotomy。因此Convex Sets的成长函数为：<span class="math inline">\(m_{\mathcal{H}(N)}=2^{N}\)</span></p><p>回到我们最初的目的，是希望找到<span class="math inline">\(M\)</span>的替代。 <img src="https://raw.githubusercontent.com/C-Harlin/MarkDownPhotos/master/learning%20from%20data/lfd_12.png%20=488x" alt="lfd_12"> 如果用生长函数来替代，而且生长函数恰好是多项式形式（polynomial），那么只要数据足够多，一定可以在概率上满足任意误差的学习。</p><h3 id="break-point">Break point</h3><p>break point是一个数值，其的直观含义是，假设集不能再将给定点“打散”（shatter，即假设集对于给定数量点的所有划分情况都可以做到）的给定点数量k，它表示了假设集的复杂性。<span class="math display">\[ m_{\mathcal{H}}(k)&lt;2^{k} \]</span>（一旦生长函数满足这一不等式，意味着假设集不能再将k个数据点打散，根据定义，k就是break point） 例如break point=3，意味着假设集无法给出三个点的所有（8种）划分情况；break point=100，意味着假设集对于N=2~99个点都可以将它们“打散”，即可以给出<span class="math inline">\(2^N\)</span>种划分情况，而当点数为100时则不能。</p><p>上面提到过，肯定有一些划分情况是假设集无法做到的，但生长函数关心的是“最好的情况”，比如有x个点，虽然这x个点存在一种划分是我的假设集所不能分开的，但没关系，因为生长函数关心的是最大化这x个点的dichotomy。 而break point针对的就是这些特殊情况，它关心的是当数据量到达多少时，就开始出现假设集无法划分的情况。</p><p>有了上述定义后，可以很方便地推出前面讲过的三个生长函数的break point。 <img src="https://raw.githubusercontent.com/C-Harlin/MarkDownPhotos/master/learning%20from%20data/lfd_13.png%20=488x" alt="lfd_13"> 值得注意到是，convex sets这个例子，对于任意数量的点，生长函数都能将其打散，所以它的break point是无穷。</p><p>进而有了以下两个结果： <span class="math display">\[ \text { No break point } \Longrightarrow m_{\mathcal{H}}(N)=2^{N} \]</span>（这是定义) <span class="math display">\[ \text { Any break point } \Longrightarrow m_{\mathcal{H}}(N) \text { is polynomial in } N \]</span>（即只要有break point，$<span class="math inline">\(mathcal{H}}(N)\)</span>就是N的多项式，这意味着可以学习）</p><p>小结：通过简单的分析我们知道了bad events是有重合的，于是希望寻找一个有效的量来代替<span class="math inline">\(M\)</span>。生长函数描述了在给定样本量的前提下，假设集最多能给出多少种不同的划分情况，它返回的是一个有限的值。所以用生长函数来代替<span class="math inline">\(M\)</span>表示在样本上的所有可能是有道理的（待证明），且进一步将无限变到有限。不过生长函数的计算太难了。相比之下，计算break point看上去要简单一些。而且结论表明（待证明），只要假设集存在一个break point，那么生长函数就是样本量的多项式形式。多项式好啊，这样学习就成为了现实。 课后问答环节有几个有意思的问题： 1.Q:上述的理论都是针对二值函数而言，实值函数呢？ A:对于实值函数是有相应的一套理论，更technical。但我不认为有必要以及有价值去讲这些。针对二值函数的理论包含了所有你需要了解的核心思想。 2.Q:假设集能把数据点打散是件好事吗？ A:There is a tradeoff during the whole class——bad and good.如果假设集能将数据打散，说明其拟合能力强，因为你给我的数据点的任何划分我都能从假设集里找到一种假设将它们分开。但拟合能力和泛化能力不一样，拟合能力太强的话，相应的泛化能力可能就没那么好。 3.Q:是否有系统的方法来确定break point？ A:no，通常是直接或间接估计的。</p><h2 id="第六课">第六课</h2><p>本课要解决的就是上面遗留的两个证明： 1.<span class="math inline">\(m_{\mathcal{H}}(N)\)</span>是多项式; 2.<span class="math inline">\(m_{\mathcal{H}}(N)\)</span>可以替换<span class="math inline">\(M\)</span>; ### <span class="math inline">\(m_{\mathcal{H}}(N)\)</span>是多项式 为了证明<span class="math inline">\(m_{\mathcal{H}}(N)\)</span>是多项式，尝试去证明<span class="math inline">\(m_{\mathcal{H}}(N)\leq\)</span>一个多项式。其中用到的一个关键量是<span class="math inline">\(B(N,k)\)</span>。这个量在上节课的最后出现过，其意义是对<span class="math inline">\(N\)</span>个点，在break point为k的限制下，所能得到dichotomies的最大值。（这里是对所有可能的假设集而言） 是生长函数的上界。 证明的过程需要动动脑筋。先从逻辑上写出<span class="math inline">\(B(N,k)\)</span>的递推关系式。 <img src="https://raw.githubusercontent.com/C-Harlin/MarkDownPhotos/master/learning%20from%20data/lfd_14.png%20=488x" alt="lfd_14"> 然后既可以从图中归纳出<span class="math inline">\(B(N,k)\)</span>的上界，也可以进一步得到<span class="math inline">\(B(N,k)\)</span>上界的解释表达式。 <img src="https://raw.githubusercontent.com/C-Harlin/MarkDownPhotos/master/learning%20from%20data/lfd_15.png%20=488x" alt="lfd_15"> 最终有如下结论： 给定假设集<span class="math inline">\(\mathcal{H}\)</span>，其break point <span class="math inline">\(\mathcal{k}\)</span>也随之确定，<span class="math display">\[ m_{\mathcal{H}}(N) \leq B(N,k) \leq\underbrace{\sum_{i=0}^{k-1}\left(\begin{array}{c}{N} \\ {i}\end{array}\right)}_{\text {maximum power is } N^{k-1}} \]</span> 因为k是一个常数，所以<span class="math inline">\(N^{k-1}\)</span>是多项式。 ### <span class="math inline">\(m_{\mathcal{H}}(N)\)</span>可以替换<span class="math inline">\(M\)</span> 教授说严谨的证明有6页之多，但有必要解释清楚其中的一些关键，以便于理解详细的证明。 需要解释清楚三件事： <img src="https://raw.githubusercontent.com/C-Harlin/MarkDownPhotos/master/learning%20from%20data/lfd_16.png%20=488x" alt="lfd_16"> 一是，我们知道<span class="math inline">\(M\)</span>是假设没有重合的，但生长函数是怎么和重合扯上关系的呢？ 二是，生长函数针对的是<span class="math inline">\(E_{in}\)</span>，但和整个空间联系的是<span class="math inline">\(E_{out}\)</span>。 三是把上述两点组合起来得到结论。</p><p>通过这张图可以形象地理解： <img src="https://raw.githubusercontent.com/C-Harlin/MarkDownPhotos/master/learning%20from%20data/lfd_17.png%20=488x" alt="lfd_17"> 图(a)的长方形表示整个数据空间，其中的点表示采样数据（<span class="math inline">\(x_1,x_2,\cdots,x_N\)</span>）。如果假设在这个点上表现为bad event，则被涂成红色。由Hoeffding不等式保证bad events的区域（图(a)中的红色区域）较小。 图(b)不同颜色的区域代表的是使不同的假设出现bad events的采样数据。这是无重合的情况，即<span class="math inline">\(M\)</span>。可以发现很快就能填满整个数据空间。 图(c)是在VC bound下的bad events的区域。</p><p>教授对图(c)进一步给出了说明：假设一个被涂了颜色的点一共会被涂上100种不同的颜色，即有100个假设会在这组采样数据上出现bad event。那么它可想而知，整个bad events的区域会缩减为原来的1%。 很多不同的假设会给出相同的dichotomy，即这些假设在有限数据点上的表现一致（对数据点的分类结果一致）！所以一旦有一个假设在这组数据点上表现出bad event，那么和它表现一致的那些假设都在该组数据点上表现为bad events。从而体现出了生长函数和重合的关系。</p><p>关于如何过渡到<span class="math inline">\(E_{out}\)</span>，只有一页slide，只是启发性的告诉了通过<span class="math inline">\(\left|E_{i n}-E_{i n}^{\prime}\right|\)</span>来解决<span class="math inline">\(\left|E_{i n}-E_{o u t}\right|\)</span> <img src="https://raw.githubusercontent.com/C-Harlin/MarkDownPhotos/master/learning%20from%20data/lfd_18.png%20=488x" alt="lfd_18"></p><p>最后是将两点组合到一起： <img src="https://raw.githubusercontent.com/C-Harlin/MarkDownPhotos/master/learning%20from%20data/lfd_19.png%20=488x" alt="lfd_19"> 图里说第一个公式是“not quite”，是因为用<span class="math inline">\(m_{\mathcal{H}}(N)\)</span>替换<span class="math inline">\(M\)</span>的想法是没问题的，但具体换的时候要对细节的地方做修改，于是就有了第二个式子。</p><h2 id="第七课vc维">第七课：VC维</h2><p>给定一个假设集<span class="math inline">\(\mathcal{H}\)</span>，它的VC维记作<span class="math inline">\(d_{\mathrm{VC}}(\mathcal{H})\)</span>，表示<span class="math inline">\(\mathcal{H}\)</span>最多能打散的点的数量。 数值上等于<span class="math inline">\(break point-1\)</span>（假设这个数量为n，不是说对所有n个点的数据集都能打散，而是至少有一组数据集能够打散），教授解释VC维和break point的区别仅在于一个是从正面描述最多能打散的数量，另一个是从反面描述达到多少之后就不能打散了。</p><p>然后证明了感知机的VC维等于其参数的个数，并解释对于感知机而言，参数的个数可以代表自由度，并举了一个特例来说明VC维的数量度量的是有效参数的个数。 <img src="https://raw.githubusercontent.com/C-Harlin/MarkDownPhotos/master/learning%20from%20data/lfd_20.png%20=488x" alt="lfd_20"> 对于较复杂的模型来说，确定VC维是件困难的事情，但可以通过模型的自由度来近似得到VC维的上界。这也就是为什么对神经网络而言，通常取<span class="math inline">\(d(\mathrm{VC})=O(\mathrm{VD})\)</span>。</p><p>回到VC不等式来研究<span class="math inline">\(N\)</span>随<span class="math inline">\(d_{\mathrm{VC}}\)</span>的变化。 最后一条经验结论是<span class="math display">\[ N \geq 10 d_{\mathrm{VC}} \]</span></p><p>最后给出了泛化界： <img src="https://raw.githubusercontent.com/C-Harlin/MarkDownPhotos/master/learning%20from%20data/lfd_21.png%20=488x" alt="lfd_21"> <img src="https://raw.githubusercontent.com/C-Harlin/MarkDownPhotos/master/learning%20from%20data/lfd_22.png%20=488x" alt="lfd_22"></p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RSA加密的数学原理</title>
      <link href="/2019/07/07/RSA%E5%8A%A0%E5%AF%86%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/"/>
      <url>/2019/07/07/RSA%E5%8A%A0%E5%AF%86%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p>欧拉___Orz <a id="more"></a>​ 用Linux已经很长一段时间了，对SSH早已不陌生。比如早先将博客部署到github上就是用SSH生成了公钥，再比如前一段时间导师让我新装了一台服务器，后来又在上面个写了点代码，远程访问也必须要用SSH。</p><p>但是吧，就像在Linux下很多莫名其妙的东西一样，大部分时候我都止步于“会用就行”，毕竟要学的东西太多，“but we only live so long”。</p><p>SSH也一样，虽然用了很多次，但一直都不明白它是什么，在干嘛。</p><p>直到在组合数学的课上，老师在讲了一点群论的知识后，说要再讲讲群论在加密中的应用，这才让我有机会在课堂上就能解决长久以来的疑惑。</p><h2 id="预备知识">预备知识</h2><h3 id="欧拉函数varphin">欧拉函数<span class="math inline">\(\varphi(n)\)</span></h3><p><span class="math inline">\(\varphi(n)\)</span>等于比<span class="math inline">\(n\)</span>小且与<span class="math inline">\(n\)</span>互质的正整数的个数。</p><p>利用容斥原理，可以得到欧拉函数的计算公式：</p><p>若<span class="math inline">\(n=p_{1}^{\alpha_{1}}p_{2}^{\alpha_{2}}\cdots p_{k}^{\alpha_{k}}\)</span>，其中<span class="math inline">\(p_{i}\)</span>为素数且各不相同。</p><p>那么，<span class="math inline">\(\varphi(n)=n(1-\frac{1}{p_1})(1-\frac{1}{p_2})\cdots (1-\frac{1}{p_k})\)</span></p><h3 id="欧拉定理">欧拉定理</h3><p>若<span class="math inline">\(a\)</span>与<span class="math inline">\(n\)</span>互质，即<span class="math inline">\((a,n)=1\)</span>，则<span class="math inline">\(a^{\varphi(n)}=1\ mod\ n\)</span></p><h3 id="群">群</h3><p>（有限）群：集合G上有一个二元运算，具有：</p><p>(a).结合律：<span class="math inline">\((xy)z=x(yz)\)</span></p><p>(b).单位元：<span class="math inline">\(∃e∈G ,s.t. ∀x∈G,xe=ex=x\)</span></p><p>(c).逆元：<span class="math inline">\(∀x∈G, ∃x^{-1}∈G\ s.t.\  xx^{-1}=x^{−1}x=e\)</span></p><p>简单来说，群就是一个特殊的集合，在上面定义了一种特殊的“乘法”，满足上述条件即可称为群。 举一个简单的例子：</p><p>给定<span class="math inline">\(n&gt;0\)</span>，令<span class="math inline">\(\frac{Z}{nZ}=\{\bar{0},\bar{1},\cdots,\bar{n-1}\}\)</span>，其中<span class="math inline">\(\bar{i}\)</span>表示除以<span class="math inline">\(n\)</span>余<span class="math inline">\(i\)</span>的数的全体。这里的<span class="math inline">\(\frac{Z}{nZ}\)</span>首先是一个集合，进一步可以验证，在“加法”下，<span class="math inline">\(\bar{i}+\bar{j}=\bar{i+j}\)</span>。因此在此“加法”下，集合<span class="math inline">\(\frac{Z}{nZ}\)</span>成为群。</p><p>借着上面这个例子，我们可以顺便给出<strong>子群</strong>的定义：</p><h3 id="子群">子群</h3><p>设<span class="math inline">\(G\)</span>是一个<span class="math inline">\(n\)</span>元群，<span class="math inline">\(H\)</span>是它的一个子群，对于<span class="math inline">\(∀x,y∈H, xy∈H\)</span>。即子群<span class="math inline">\(H\)</span>就是<span class="math inline">\(G\)</span>的一个子集，同时还要满足封闭性、结合律、有单位元和逆元。</p><p>承接上一个例子，我们取<span class="math inline">\(\frac{Z}{nZ}\)</span>中所有的逆元，得到一个新的集合：<span class="math display">\[(\frac{Z}{nZ})^*=\{\frac{Z}{nZ}中的可逆元\}\]</span> 容易验证，<span class="math inline">\((\frac{Z}{nZ})^*\)</span>是<span class="math inline">\(\frac{Z}{nZ}\)</span>的子群。</p><p>虽然这里只是将<span class="math inline">\((\frac{Z}{nZ})^*\)</span>作为子群的一个示例给出，但不要小看它。<span class="math inline">\((\frac{Z}{nZ})^*\)</span>有一个接下来要用到的特殊性质，即：<span class="math display">\[ \bar{i}可逆\Leftrightarrow(n,i)=1 \]</span> 也就是说，<span class="math inline">\((\frac{Z}{nZ})^*\)</span>中的所有元素都是与<span class="math inline">\(n\)</span>互质且比<span class="math inline">\(n\)</span>小的正整数的同余数构成的。由欧拉公式，与<span class="math inline">\(n\)</span>互质且比<span class="math inline">\(n\)</span>下的正整数的个数为<span class="math inline">\(\varphi(n)\)</span>，所以<span class="math inline">\((\frac{Z}{nZ})^*\)</span>的阶（即群里面元素的个数）为<span class="math inline">\(\varphi(n)\)</span></p><p>有了上述的数学基础后，我们就可以揭开RSA加密算法的面纱了。</p><h2 id="rsa算法">RSA算法</h2><p>RSA加密算法可以称得上是现代密码学的基石。</p><p>传统的加密方法的思想可以参照谍战片中的桥段，即双方约定一种加密规则，发送方用该规则对情报加密，接收方按照规则对情报解密。但这套方法的弊端在于，必须保证加密规则不泄露，一旦加密规则泄露即意味着信息被破解。更可怕的是，你无法知道加密规则是否已经泄露了。</p><p>而RSA加密算法则颠覆了这一过程。简单来说，你有两把钥匙，分别是公钥和私钥。公钥是公开的，而私钥是私密的。发送方用你的公钥对信息进行加密，你收到加密信息后，用私钥对信息进行解密。其他人就算在中途解惑了加密信息也无从下手，因为私钥只有你自己知道。只要私钥安全就能保证信息安全。</p><p>我们来看具体加密过程。假设甲要给乙传送正整数m，这里要求<strong>m小于n且与n互质</strong>。</p><ol type="1"><li><p>第一步 选取两个很大的素数<span class="math inline">\(p\)</span>、<span class="math inline">\(q\)</span>，令<span class="math inline">\(n=pq\)</span>，通常<span class="math inline">\(n\)</span>会有上百位</p></li><li><p>第二步 还记得我们之前的提到的关于子群的例子吗？这里我们参照<span class="math inline">\((\frac{Z}{nZ})^*\)</span>的形式，取<span class="math inline">\(\bar{e}\in(\frac{Z}{\varphi(n)Z})^*\)</span>，即<span class="math inline">\(e\)</span>与<span class="math inline">\(\varphi(n)\)</span>互质。 这里的<span class="math inline">\(e\)</span>将用来构成公钥。</p></li><li><p>第三步 因为<span class="math inline">\(\bar{e}\in(\frac{Z}{\varphi(n)Z})^*\)</span>，那么由群关于逆元的性质，必然存在<span class="math inline">\(\bar{d}\in(\frac{Z}{\varphi(n)Z})^*\ s.t.\ \bar{e}\bar{d}=\bar{1}，即ed=1\ mod\ \varphi(n)\)</span>。 这里的<span class="math inline">\(d\)</span>将用来构成私钥。</p></li><li><p>第四步 发送方用公钥对整数<span class="math inline">\(\bar(m)\)</span>加密并传输给接收方：<span class="math display">\[ \bar{m} \Rightarrow \bar{m}^e \]</span></p></li><li><p>第五步 用私钥进行解密：<span class="math display">\[ \bar{m}^e \Rightarrow \bar{m}^{ed} =\bar{m}^{\varphi(n)k+1}=(\bar{m}^{\varphi(n)})^k *\bar{m} \]</span>因为m与n互质，所以由欧拉定理，<span class="math inline">\(\bar{m}^{\varphi(n)}=\bar{1}\)</span>。故：<span class="math display">\[ \bar{m}^e \Rightarrow \bar{m}^{ed} =\bar{m}^{\varphi(n)k+1}=(\bar{m}^{\varphi(n)})^k *\bar{m}=\bar{m} \]</span></p></li></ol><p>至此，我们便完成了对m的加密和解密。 （注意，推导里用的是m的同余数<span class="math inline">\(\bar{m}\)</span>，对<span class="math inline">\(\bar{m}\)</span>成立，当然也对m成立）</p><p>但剩下一点收尾的工作。</p><p>上述推导基于的假设是m与n互质。那要是不互质，还有办法用RSA加密吗？答案是肯定的。证明如下：</p><p><span class="math inline">\(\because p、q为素数且n=pq\)</span></p><p><span class="math inline">\(\therefore 若m与n不互质，则m=pl\ 或\ ql，l\in Z，不妨设m=pl，则：\)</span> <span class="math display">\[ \bar{m}^{ed}=\bar{pl}^{\varphi(n)k+1}=\bar{pl}^{(p-1)(q-1)k+1} \]</span></p><p><span class="math inline">\(\because p、q为素数\)</span></p><p><span class="math inline">\(\therefore 由欧拉定理(或费马小定理)，\bar{pl}^{q-1}=\bar{1}，即\bar{pl}=1\ mod \ q\)</span></p><p><span class="math inline">\(\therefore \bar{pl}^{(p-1)(q-1)k+1}=[\bar{pl}^{q-1}]^{(p-1)k}*\bar{pl}=\bar{pl}\)</span></p><p><span class="math inline">\(\therefore \bar{m}^{ed}=pl\ mod\ q\)</span></p><p><span class="math inline">\(\therefore \bar{m}^{ed}=tq+pl\)</span></p><p><span class="math inline">\(\therefore (pl)^{ed}=tq+pl\)</span> 易得，<span class="math inline">\(t\)</span>可以被<span class="math inline">\(p\)</span>整除</p><p><span class="math inline">\(\therefore (pl)^{ed}=t^{&#39;}pq+pl=t^{&#39;}n+pl=pl\ mod\ n\)</span> 即，<span class="math inline">\(m^{ed}=m\ mod\ n\)</span></p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>矩阵广义逆求解线性方程组</title>
      <link href="/2019/06/13/%E7%9F%A9%E9%98%B5%E8%AE%BA%E5%B9%BF%E4%B9%89%E9%80%86%E6%B1%82%E8%A7%A3%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84%20/"/>
      <url>/2019/06/13/%E7%9F%A9%E9%98%B5%E8%AE%BA%E5%B9%BF%E4%B9%89%E9%80%86%E6%B1%82%E8%A7%A3%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84%20/</url>
      
        <content type="html"><![CDATA[<p>还在用高斯消元法解线性方程组？ <a id="more"></a></p><p>说起解线性方程组，这可是线性代数的基础内容。高斯消元法如果只学过线性代数的话</p><h2 id="背景">背景</h2><p>逆矩阵的概念只对非奇异矩阵才有意义，但是在实际问题中，我们遇到的矩阵不一定是可逆方阵，因此我们希望能将逆矩阵的概念推广到非方阵、奇异矩阵上。具体的：</p><ol type="1"><li>这个矩阵对于奇异矩阵甚至长方形矩阵都存在；</li><li>它具有通常逆矩阵的一些性质</li><li>当矩阵非奇异时，它还原到通常的逆矩阵</li></ol><p>满足以上三个条件的矩阵称为<strong>广义逆矩阵</strong> （以下都简称为广义逆）</p><p>广义逆的概念最初由E.H.Moore在1920年提出，但其后的三十年时间，该理论都没有得到重视。直到1955年，R.Penrose以更明确的形式给出了Moore的广义逆的定义后，广义逆的研究才进入了一个新时期。随着广义逆在数理统计、系统理论、优化计算和控制论等领域中的应用，大大推动了广义逆的理论与应用研究。</p><p>课上老师评价道，好的理论不一定会马上得到认可，如果你真的觉得自己的理论是有价值的，那就坚持下去吧！</p><h2 id="penrose的广义逆定义">Penrose的广义逆定义</h2><p>设矩阵<span class="math inline">\(A\in C^{m×n}\)</span>，若矩阵<span class="math inline">\(X\in C^{n×m}\)</span>满足如下四个方程： <span class="math display">\[ AXA=A \tag {i} \]</span> <span class="math display">\[ XAX=X \tag {ii} \]</span> <span class="math display">\[ (AX)^H=AX \tag {iii} \]</span> <span class="math display">\[ (XA)^H=XA \tag {iv} \]</span> 的<font color="#0099ff">某几个或全部</font>，则称X为A的广义逆矩阵；满足全部四个方程的广义逆矩阵X称为A的Moore-Penrose逆，记为<span class="math inline">\(A^＋\)</span></p><p>对于任意的<span class="math inline">\(A\in C^{m×n}\)</span>，<span class="math inline">\(A^＋\)</span>存在且唯一。这里不加证明。</p><p>上述四个方程看起来并不方便记忆，所以可以按照以下思路理解：</p><p>对于一个非奇异矩阵<span class="math inline">\(A\)</span>，它的逆矩阵<span class="math inline">\(X\)</span>应该满足：<span class="math inline">\(AX=I\)</span> 但对于奇异矩阵或长方形矩阵<span class="math inline">\(A\)</span>来说，它的广义逆矩阵<span class="math inline">\(X\)</span>不一定满足<span class="math inline">\(AX=I\)</span>，但使得<span class="math inline">\(\underline{AX}A=A\)</span>，那么我们认为<span class="math inline">\(AX\)</span>起到了单位矩阵（<span class="math inline">\(AX=I\)</span>）的效果。</p><p>其余的三个方程同理。</p><h2 id="求一个矩阵的广义逆">求一个矩阵的广义逆</h2><p>目前我知道的有两个方法，分别基于(1).奇异值分解；(2).满秩分解。</p><p>(1).基于奇异值分解</p><p>对A做奇异值分解：<span class="math display">\[ A=UDV^H， \quad \begin{bmatrix}\sigma_1 &amp;  &amp;  &amp; \\  &amp; \ddots  &amp; &amp; O \\  &amp;  &amp; \sigma_r &amp; \\ &amp;O&amp;&amp;O\end{bmatrix}_{m×n} \]</span> 其中<span class="math inline">\(\sigma_i &gt;0(i=1,\cdots,r)\)</span>是A的奇异值，U和V分别是m阶和n阶酉矩阵。 取<span class="math display">\[ X=V\begin{bmatrix}\sigma^{-1}_1 &amp;  &amp;  &amp; \\  &amp; \ddots  &amp; &amp; O \\  &amp;  &amp; \sigma^{-1}_r &amp; \\ &amp;O&amp;&amp;O\end{bmatrix}_{n×m}U^H \]</span> 可以验证<span class="math inline">\(X\)</span>满足四个Penrose方程。可见，<span class="math inline">\(A^＋\)</span>总是存在的。</p><p>(2).基于满秩分解</p><p>对A做满秩分解：<span class="math display">\[ A_{m×n}=F^{m×r}_r×G^{r×n}_r \]</span> 令<span class="math inline">\(F^＋=(F^HF)^{-1}F^H，G^＋=G^H(GG^H)^{-1}\)</span></p><p>则<span class="math inline">\(A^{＋}=G^{＋}F^{＋}\)</span></p><h2 id="广义逆矩阵与线性方程的求解">广义逆矩阵与线性方程的求解</h2><p>如果存在<span class="math inline">\(x\)</span>使得非齐次线性方程组<span class="math inline">\(Ax=b\)</span>成立，则称该方程组<span class="math inline">\(\underline{相容}\)</span>，否则称为<span class="math inline">\(\underline{不相容}或\underline{矛盾方程组}\)</span>。</p><p>我们关心以下四个问题：</p><ol type="1"><li>相容的条件是什么？通解怎么求？</li><li>如果相容，其解可能有无穷多个，求<font color="#F08080">极小范数解</font>（即<span class="math inline">\(min||x||,\ s.t\ Ax=b\)</span>）</li><li>如果不相容，求矛盾方程组的<font color="#F08080">最小二乘解</font></li><li>最小二乘解不唯一，求其<font color="#F08080">极小范数最小二乘解</font></li></ol><p>这里不加证明地给出下列定理。</p><h3 id="线性方程组的相容性和通解">线性方程组的相容性和通解</h3><p>定理：设<span class="math inline">\(A\in C^{m×n}，B\in C^{p×q}，D\in C^{m×q}\)</span>，则矩阵方程<span class="math inline">\(AXB=D\Leftrightarrow AA^{1}DB^{1}B=D\)</span>，其中<span class="math inline">\(A^{(1)}\in A\{1\}，B^{(1)}\in B\{1\}\)</span>。</p><p>通解为<span class="math inline">\(X=A^{(1)}DB^{(1)}+Y-A^{(1)}AYBB^{(1)}\)</span>，其中<span class="math inline">\(Y\in C^{n×p}\)</span>任意。</p><h3 id="相容线性方程组的极小范数解与广义14-逆">相容线性方程组的极小范数解与广义{1,4}-逆</h3><p>定理：设方程组<span class="math inline">\(Ax=b\)</span>相容，则<span class="math display">\[ x=A^{(1,4)}b \]</span>是极小范数解，其中<span class="math inline">\(A^{(1,4)}\in A\{1,4\}\)</span>。</p><h3 id="矛盾方程组的最小二乘解与广义13-逆">矛盾方程组的最小二乘解与广义{1,3}-逆</h3><p>定理：设<span class="math inline">\(A\in C^{m×n}，b\in C^{m}，A^{(1,3)}\in A\{1,3\}\)</span>，则<span class="math inline">\(x\in A^{(1,3)}b\)</span>是方程<span class="math inline">\(Ax=b\)</span>的最小二乘解。</p><h3 id="矛盾方程组的极小范数最小二乘解与广义逆矩阵a">矛盾方程组的极小范数最小二乘解与广义逆矩阵<span class="math inline">\(A^+\)</span></h3><p>定理：设<span class="math inline">\(A\in C^{m×n}，b\in C^{m}\)</span>，则<span class="math inline">\(x=A^+b\)</span>是方程组<span class="math inline">\(Ax=b\)</span>的极小范数最小二乘解。</p><p>有了上述定理后，**当我们求解线性方程组<span class="math inline">\(Ax=b\)</span>时，先求出<span class="math inline">\(A\)</span>矩阵的广义逆矩阵<span class="math inline">\(A^+\)</span>，具体的两种求法在上面已经给出。</p><p>然后计算<span class="math inline">\(AA^+b\)</span>是否等于<span class="math inline">\(b\)</span>。</p><p>如果线性方程组相容的话，那么一定满足<span class="math inline">\(AA^+b=b\)</span>，同时求出的<span class="math inline">\(A^+\)</span>就是方程组的解；</p><p>反之，如果<span class="math inline">\(AA^+b\neq b\)</span>，那么方程组无解，求出的<span class="math inline">\(A^+\)</span>就是方程组的极小范数最小二乘解**</p><p>平时手算解三四阶的线性方程组的话，还是用高斯消元法比较简单。不过，当矩阵的规模非常大时，就不能指望靠高斯消元法来求解线性方程组了，幸好还有求诸广义逆来求解。</p><h2 id="结语">结语</h2><p>当我们的思绪再次回到1920年，谁也不知道广义逆这样抽象的理论有何用。</p><p>数学家们造好了形状各异、精巧十足的积木，人类的求知的天梯才得以一阶一阶地向上搭建。</p><p>有几块积木暂时没被用到，但可能会有那么一天，到了某一阶，人们突然发现，之前的那块看似没用的积木用在这里刚刚好啊！ <br> <br> <br> 参考文献：</p><p>[1].矩阵论/程云鹏，西北工业大学出版社, 1989</p><p>[2].lecture note，张世华</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一场由数据类型引发的灾难</title>
      <link href="/2019/04/30/%E7%94%B1%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%BC%95%E5%8F%91%E7%9A%84%E7%81%BE%E9%9A%BE/"/>
      <url>/2019/04/30/%E7%94%B1%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%BC%95%E5%8F%91%E7%9A%84%E7%81%BE%E9%9A%BE/</url>
      
        <content type="html"><![CDATA[<p>程序员最讨厌的两件事：给代码写注释，读没有注释的代码</p><p>(ง •̀_•́)ง┻━┻掀桌 <a id="more"></a>​</p><h2 id="背景">背景</h2><p>事情的起因是做大数据系统这门课的作业，其中要用到老师自己写的一个开源同步图计算系统Graphlite。所以免不了要读陌生的代码。 怎么说呢，老师给代码的注释也就满足刚刚能使用……对于很多细节的东西就没了说明。 例如，代码里有很多封装好的函数倒是说明了功能，但对更细节的东西像数据类型的选择之类的，则没有说明。 毕竟是个人项目，没有完善的文档也可以理解……</p><h2 id="噩梦的开始">噩梦的开始</h2><p>我一开始太大意了。因为这个作业目的就是在原有例程的基础上修改，来实现自己的功能。 但坑人的地方在于老师没说哪里不能改。 所以我就按照自己的需求把代码里定义好的函数的的数据类型修改了。 OK，下面开始进入噩梦。</p><h2 id="噩梦">噩梦</h2><p>首先是运行超时，怎么也跑不出结果。</p><p>不过这个难不倒我，经过多次试验后发现是修改了关键代码处数据类型的问题，改回来后就可以运行。 但是改回来的只是被我修改的众多数据类型的一部分。</p><p>虽然程序能运行了，但是却又停不下来了……也就是说终止条件设置的有问题。</p><p>设计的是从aggregator读取当前超步的全局变量，即误差，若误差为0则停止。但坏就坏在了我将这个变量强行从double型变成了int型： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int global_val = *(int*)getAggrGlobal(0);</span><br></pre></td></tr></table></figure></p><p>我把一个按double型存储的数据，强行用int型的格式读取了出来，那么读出来的值自然是不对的。</p><p>至于为什么最后给改过来了，是因为发现可能是数据类型的问题，索性就将所有擅自修改过的数据类型都改了回来……真是瞎猫碰上死耗子</p><p>（我觉得有必要专门研究下数据类型转换……）</p><p>让我发现是数据类型出了问题的突破口是这里： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">value_int = (int)value; </span><br><span class="line">int n = sprintf(s, &quot;%lld: %d\n&quot;, (unsigned long long)vid, value_int);</span><br></pre></td></tr></table></figure></p><p>这是改正后的代码，而改正前是： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int n = sprintf(s, &quot;%lld: %d\n&quot;, (unsigned long long)vid, value);</span><br></pre></td></tr></table></figure></p><p>也就是说，我强行将一个double型数据按照整型数据的格式打印了出来！</p><p>就是这个困扰了我一天的问题！莫名打印出设定范围之外的数。</p><p>最后是在打印另一个变量观察输出时才发现了端倪。找到了问题所在，就乖乖的把数据类型都改了回去，顺利解决作业……</p><p>事实证明，printf才是最强的debug工具……</p><h2 id="黎明">黎明</h2><p>现在回过头来看，这个作业本应该昨天就搞定的，但在我观察到奇怪的输出值后却并没有认真思考原因。</p><p>事实上，每次编译时，编译器已经就那个出错的地方给了我warning，但由于我经历过太多无足轻重的warning，所以不由自主地忽略了这一信息。</p><p>所以这次的教训值得吸取，没有这一天时间的浪费，我也意识不到是这里出了问题。</p><p>还是要经历过之后才有长进。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据类型 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>生活令你沮丧？是时候读读大师与玛格丽特了</title>
      <link href="/2018/11/24/%E5%A4%A7%E5%B8%88%E4%B8%8E%E7%8E%9B%E6%A0%BC%E4%B8%BD%E7%89%B9/"/>
      <url>/2018/11/24/%E5%A4%A7%E5%B8%88%E4%B8%8E%E7%8E%9B%E6%A0%BC%E4%B8%BD%E7%89%B9/</url>
      
        <content type="html"><![CDATA[<p>一个月前的这个时候是我近期情绪的一个低谷。那段时间遇到了不少shitty的人和事，心中郁郁难平。一天，偶然刷微博看到了这个标题，顿时就被吸引，指望着被这本书治愈。</p><a id="more"></a>​<center>一</center><p>1930年的苏联。肃反、骚乱、饥荒……空气中弥漫着不安。被视为国家英雄的诗人马雅可夫斯基，在莫斯科寓所开枪自杀。一个文学的肃杀时代到来了[1]。 从1927年开始，小说家布尔加科夫就遭到苏联文学界的封禁。他的讽刺笔法触怒了“拉普”（全俄无产阶级作家联合会）头头阿维尔巴赫。于是铺天盖地的批评席卷而来，他被指控为“严重反对苏维埃”。到1929年，他的任何作品都无法通过审查。但在彼时，他已经开始创作《大师与玛格丽特》，这本后来被誉为魔幻现实主义的开山之作，同时也被誉为20世纪最好的俄语小说之一。 1930年三月，当得知自己创作的剧本《Кабала святош》也被禁之后，布尔加科夫彻底绝望了，在火炉中焚毁了《大师与玛格丽特》的手稿。 该年3月28日，贫困潦倒的布尔加科夫给斯大林写信，希望得到莫斯科艺术剧院助理导演职位，“如果不能任命我做助理导演，我请求当个在编配角演员；如果不行，就当个管剧务的工人；再不行，请苏联政府以任何方式尽快处置我，只要处置就行……” 即使眼前的处境困难重重，他依然还保留着作品被禁作家的桀骜，“尽快处置我，只要处置就行”。 同年四月十八日，斯大林拨通了布尔加科夫家的电话，与他进行了简短的交谈，然后布尔加科夫成了莫斯科艺术剧院的一名助理导演。 于是，一位鼎鼎有名的作家从公众的视野里消失，莫斯科的小剧院里多了一名叫布尔加科夫的普通职员。 作品被禁的第二年，也就是1931年，布尔加科夫与伊莱娜·希洛夫斯卡亚结婚。伊莱娜正是《大师与玛格丽特》中玛格丽特的原型。 结婚的同年，布尔加科夫开始重写《大师与玛格丽特》，彼时他的生命只剩下最后十年。六年写成，在他的妻子的帮助下，他继续修改作品，直到死前四周。他的妻子在1940到1941年间完成了修改。期间还著有其他戏剧、评论、小说、翻译。它们无一发表，只拥有包括伊莱娜在内的寥寥几位读者。 就像疾病使普鲁斯特回到写作，孤独使卡夫卡回到写作那样，厄运将布尔加科夫与荣誉、富贵分开了，同时又将真正的写作赋于了他，给了他另一种欢乐，也给了他另一种痛苦。回到了写作的布尔加科夫，没有了出版，没有了读者，没有了评论，与此同时他也没有了虚荣，没有了毫无意义的期待。他获得了宁静，获得了真正意义上的写作。[2]</p><p>1940年——整整十年封杀之后，布尔加科夫因家族遗传的肾病去世。1966年，《大师与玛格丽特》终于出版，但删改严重，被删章节以手抄本形式秘密流传。1967年，法兰克福的一位出版人在此基础上出版了较完全的版本。而在苏联，布尔加科夫的祖国，第一个完全版本的出现，则要等到1973年。这时，距离作者过世已有三十三年。</p><center>二</center><p>撒旦带着它的四名随从来到了1930年左右的莫斯科，开启了整个故事的第一条主线。1930年，恰巧也是布尔加科夫被封禁的年份。 在《圣经·约伯记》中撒旦表现为上帝的众侍者之一，其司职是在上帝的同意下来到人间观察世人，并对人进行种种考验。 这一点在第十二章得到了验证。化身为魔术师沃兰德的撒旦在剧院内说，比起公共汽车、电话这些新奇的东西，他更关心的是莫斯科居民的内心是否发生了变化。于是一出出的闹剧接二连三地上演，谎言被戳穿，贪欲被揭露，整个莫斯科陷入到了不安与紧张之中。</p><p>与莫斯科城里的热闹相反的是故事的第二条主线。在安静的莫斯科郊外的精神病医院里住着一位自称是大师的人。他因为创作了一本关于本丢•彼拉多与耶舒阿（耶稣）的小说而遭到批评家的指责。批评的文章越来越多，大师从起初的不以为意，到惊讶于这些批评的虚张声势和色厉内荏，再到后来的恐惧阶段，他被焦虑的情绪所笼罩。正如布尔加科夫所写：“怯懦是人类缺陷中最最可怕的缺陷。”大师是怯懦的，他烧毁了自己小说的手稿，躲进了精神病医院。 大师的形象何尝不是布尔加科夫自己。正像余华所写的那样，大师的形象是布尔加科夫自身现实和作品之间的唯一联系，这种联系是基于布尔加科夫对自己的虚幻理解。这种虚幻的理解使得联系变得脆弱，正是因为其脆弱，大师这个人物在布尔加科夫笔下才会如此虚幻。</p><p>与大师的怯懦相比，本书的另一位主角，大师的情人，玛格丽特，则显得异常勇敢。她的出现使大师的内心获得了无与伦比的宁静；她鼓励大师完成创作，说她的全部生命都寓于这部小说中；她从火炉中救出残存的小说原稿，正如布尔加科夫的妻子伊莱娜拯救了《大师与玛格丽特》一样。</p><p>为了拯救大师，玛格丽特不惜变身魔女，主持撒旦的午夜舞会。整部小说也在玛格丽特赤身裸体地飞翔在莫斯科的夜空时达到了高潮。 这是一段无比美妙的描述。只需要一点点的想象力，你就能借着布尔加科夫的文字飞翔在“电灯灯光构成的湖泊”上、飞过起伏延绵的丘陵，“脚尖几乎可以触到高大的松树树梢”。 她“眼眸中有着女巫的目光、脸上凶残又冷酷”。然而，舞会结束后，她居然愿意牺牲与大师的重聚，去帮助女鬼弗丽达，使她免于永恒的惩罚。魔鬼沃兰德对此评价道：“仁慈有时候出其不意、鬼鬼祟祟地从最小的缝隙里爬进来。”凶残冷酷又仁慈，唯独没有怯懦。</p><p>作为主持舞会的回报，大师与玛格丽特重聚。而撒旦也在莫斯科的一片火光中准备结束此次旅行。 小说结尾处，利未•马太说，耶稣已读了大师的小说，请魔鬼“带走大师并赐给他安宁。”沃兰德问：“你为什么不自己把他带到光明之处？”利未带着几分伤感说：“他不应得到光明，他只配得到安宁。”</p><p>大师死了，跟随魔鬼离开世界，他和他的爱人得到了永恒的家园，拥有了从未有过的宁静。“大师过去的记忆，他那焦虑不安的、备受针刺的痛苦回忆慢慢开始模糊。有一个人使大师解脱了，正如他自己刚刚使自己创造的小说主人公得到解脱一样。”大师为彼拉多的故事添上了结局——他“宽恕了占星术之王的儿子、残酷的第五任犹太总督、骑士本丢•彼拉多。”</p><center>三</center><p>作为魔幻现实主义的开山之作，布尔加科夫的文字充满了魔力。他总可以毫不费力地将你带入到他所创造的世界中。 你似乎可以看到那饱含着水分和雷电的铅一般的乌云，闪着电光奔腾着扑向两千年前耶路撒冷；恍惚间又好像可以嗅到暴雨过后的莫斯科郊外那雨后青草混着泥土的气息；抑或是在一众人骑着魔法唤出的黑马飞驰昼与夜的边界时感受到疾风掠过皮肤时的凉意。 三条独立的主线在小说的结尾处被紧紧地捏合到了一起，在情节上归于圆满，在情感上完成了释放。 在布尔加科夫去世了三十三年后，这本伟大的小说才得以为世人所知。也许布尔加科夫在决定写这本小说时，就没有指望它会被出版。我更愿意相信这是布尔加科夫写给自己的书。一位前途被断绝的作家，一个生命即将走到尽头的病患，在人生的最后一本书里实现了自己与世界和解。</p><p>嘿，你瞧，大师的那本饱受批评的小说最终不也得到了诸神的认同吗？本丢•彼拉多在一万两千个满月的折磨后，不也终于踏上了梦中那条月光形成的路吗？</p><p>"只有那些在这云烟中辗转徘徊过的人，只有死亡之前经受过众多磨难的人，只有肩负着力不胜任的重荷在这片大地上翱翔过的人，只有他们才知道这一切。只有已经疲倦的人才了解这一切。因此他才能无所惋惜、毫不遗憾地离开这大地的云烟，离开它的池沼与河川，恰然地投入死神的怀抱，因为他知道，只有她，只有死神，才能给予他宁静和平安"。</p><p>参考文献： [1].任晓雯：只管静默，不要作声——读《大师与玛格丽特》 [2].余华：布尔加科夫与《大师和玛格丽特》 [3].维基百科：大师与玛格丽特、米哈伊尔·阿法纳西耶维奇·布尔加科夫</p>]]></content>
      
      
      <categories>
          
          <category> 读书 </category>
          
          <category> 阅读笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Deep Residual Learning for Image Recognition 译文/中文版</title>
      <link href="/2018/06/07/Deep%20Residual%20Learning%20for%20Image%20Recognition/"/>
      <url>/2018/06/07/Deep%20Residual%20Learning%20for%20Image%20Recognition/</url>
      
        <content type="html"><![CDATA[<p>  作为一个刚刚接触深度学习的新人，残差网络给我留下了非常深的印象。<br>  适逢学校对于毕业设计要求翻译一篇外文文献，抱着致敬经典的心情，特此翻译该文章。<br><a id="more"></a>   网上所能找到的两篇译文中，有一篇翻译得还不错，不过中间有不少地方进行了意译；另一篇就比较糟糕了，像是机器翻译的结果。<br>  本文在这两篇翻译的基础上，对全文进行了翻译。</p><center>摘要</center><p>  越深层的神经网络往往越难训练。我们在此提出一个残差学习框架以减轻网络的训练负担，这些网络比以往使用的网络要深得多。我们明确地将层改为学习关于输入的残差函数，而不是学习未知的函数。我们提供了全面的实验数据来证明，残差网络更容易被优化，并且在深度加深时获得更高的精度。在ImageNet数据集上，我们评测了一个深达152层的残差网络——层数是VGG的8倍，却依旧拥有比VGG更低的复杂度。残差网络在ImageNet测试集上总体实现了3.57%的错误率，这一结果获得了ILSVRC2015分类任务的第一名。我们在CIFAR-10数据集上分析了100层和1000层的网络。<br>  对许多视觉识别任务来说，表征深度表示往往是最重要的。得益于这种极深的表征，我们在COCO物体检测数据集获得了28%的相对提升。深度残差网络是我们在ILSVRC和COCO 2015竞赛上提交模型的基础，我们还获得了ImageNet物体检测，ImageNet定位，COCO检测和COCO图像分割的第一名。</p><center>1 简 介</center><p>  深度卷积神经网络在图像分类问题上取得了一系列突破。深度网络轻而易举地在一个端到端多层结构中整合了低、中、高三种不同级别的特征和分类器，并且特征的“级别”可以靠堆叠层数来扩充。最近的研究表明，网络深度至关重要。在ImageNet竞赛中取得领先地位一些成果都不约而同地使用了“非常深”的网络模型，从16层到30层不等。其他一些重要的视觉识别问题也同样得益于非常深的网络模型。<br>  在深度重要性的驱使下，一个问题浮出水面：堆叠更多的层是否一定能学得更好的网络？解答这一问题的一个障碍就是臭名昭著的梯度消失/爆炸问题。它从一开始就阻碍着收敛。然而这一障碍，在很大程度上已经可以通过标准初始化和正则化层得到解决，从而确保几十层的网络利用SGD和反向传播能够收敛。<br>  但当更深层的网络开始收敛时，退化问题又暴露了出来：随着神经网络深度的增加，精确度开始饱和（这本不足为奇），然后会迅速的降低。出人意料的是，这种退化并不是由过拟合导致的，并且在深度模型上增加更多的层反而会导致更大的训练误差，正如文章[11,42]所述，并通过我们的实验将得以充分证实。图1展示了一个典型的例子。</p><p>  退化（训练精度）现象表明，不是所有的系统都同样易于优化。让我们考虑一个浅层架构和一个与之对应的增加了更多层的深层架构。有一个解决方案可以用来构建深层模型：添加的层是恒等映射，其他层从训练好的浅模型中复制而来。我们推测，通过这种构建方式得到的深层模型应该不会比浅层模型产生更高的训练误差。但实验结果表明，我们手头上的方案都找不到同样好或是更好的解（或者是无法在合理的时间里做到）。<br>  在本文中，我们通过引入一个深度残差学习框架解决了退化问题。我们不再期望每一层层能够直接拟合一个潜在的映射，而是明确的让这些层去拟合残差映射。从形式上看，令H(x)来表示期望的潜在映射，我们让堆叠的非线性层去拟合另一个映射F(x)≔H(x)-x。此时原映射H(x)就可以改写成F(x)+x。我们假设残差映射比原映射更容易被优化。极端情况下，如果一个恒等映射是可优化的，那么将残差减小到0要比用堆叠非线性层来拟合恒等映射容易的多。<br>  F(x)+x可以通过带有“快捷连接”的前馈网络来实现（如图2）。快捷连接是指那些跳过一个或多个层的通路。在我们的模型中，快捷连接仅仅简单执行恒等映射，它们的输出被累加到叠加层的输出中。恒等快捷连接既没有增加额外的参数也没有增加计算复杂度。整个网络依然可以用SGD+反向传播来做端到端的训练，并且可以很容易地用常见的库来实现（比如Caffe）而不用修改slover配置（slover是caffe中的核心slover.prototxt）</p>  我们在ImageNet数据集上做了全面的实验，来证实退化问题以及评估我们的方法。我们证明了：1.我们的超深残差网络易于优化，不过相应的普通网络（简单的堆叠层）当在深度增加时，表现出更高的训练误差；2.我们的深度残差网络可以轻松的享受深度增加所带来的精度增加，其效果要远远优于以前的那些网络。<br>  类似的现象也同样出现在CIFAR-10数据集上，这表明我们提出的训练方法的优化难度和效果并不仅仅适合于某一类特定的数据集。我们在这个数据集上成功训练出超过100层的模型，并且还探索了超过1000层的模型。<br>  在ImageNet分类数据集上，我们用超深残差网络获得了出色的结果。我们152层的残差网络是ImageNet的参赛网络中最深的，然而却拥有比VGG网络更低的复杂度。我们最终的效果是测试集上3.57%的错误率，以此摘取了ILSVRC2015物体分类的第一名。这种超级深的表示方法在其他识别任务中也有良好的泛化能力，使我们进一步赢得了ImageNet检测, Imagenet定位,COCO检测 COCO分割多个比赛的第一名。这充分证明了残差学习的原则是可泛化的，我们同样期望残差学习的方法能用在其他的视觉和非视觉问题上。<center>2 相关工作</center><p>残差表示：<br>  在图像识别任务中，VLAD[18]是用基于词典的残差向量来进行特征编码的一种表达形式，fisher向量可以看作是VLAD的一个概率版本，在图像检索和分类中它们都是强有力的浅层表达。对于向量量化，残差向量编码要比原始向量编码更有效。<br>  在低级视觉和计算机图形学中，为了求解偏微分方程（PDE），通常是使用多重网格（Multigrid）法，把系统重新表达成不同尺度的子问题，每个子问题负责求解粗细尺度之间的残差解。除此之外，另一种求解PDE的方法是分层基预处理[45,46]，是基于表达两个尺度之间残差向量的变量。在[3,45,46]中证明了这些求解器要比那些没有利用残差性质的普通求解器收敛地快得多。这些研究表明，一个好的重新表达或者预处理能够简化优化问题。</p><p>快捷连接：<br>  实践和理论都对 “快捷连接”做了长期的研究。在训练多层感知器网络（MLP）的早期实践中，就是添加一个从网络输入直连到输出的线性层[34,49]。在[44,24]中，少量的中间层直接与辅助分类器相连以解决梯度消失/爆炸问题，论文[39,38,31,47]中提出一系列方法，利用快捷连接将层的响应、梯度、传递误差集中起来。在论文[44]中，一个“incepion” 层是由一个快捷分支和少量较深的分支组成。<br>  与我们同期的工作，如“Highway network”[43,42]，展示了带有门限函数的快捷连接。这些门函数是数据相关的并且带有参数。相反，我们的恒等快捷连接没有参数。当一个门限快捷连接呈关闭状态时（接近0），highway network中的层就表现为非残差函数。相反的，我们的方法总是学习残差函数；在学习残差函数时，我们的自身快捷连接是永不关闭的，因此所有的信息总能通过。与借此学习残差函数。此外highway network并不能实现精度随深度的增加而提高（比如超过100层后）。</p><center>3 深度残差网络</center><p>3.1 残差学习<br>  我们假设H(x)是若干个堆叠层将要去拟合的潜在映射（不一定要整个网络），其中x表示第一层的输入。假如多个非线性层可以渐进逼近复杂的函数，那么这等价于它们同样能渐进逼近残差函数，例如，H(x)-x（假设输入和输出维度相同）。所以与其期望这些层去逼近H(x)，不如让它们去逼近残差函数F(x)≔H(x)-x。原方程则变为F(x)+x，尽管这两种形式都应该能渐进逼近目标函数（根据假设），但是学习的难易程度却不相同。<br>  这种重构的动机是由于退化问题这个反直觉的现象（图1，左）。正如我们在介绍中讨论的，如果添加的层被构造为恒等映射，那么一个更深模型的训练误差不应该大于与之对应的较浅模型。退化问题表明，求解器可能很难使用多个非线性层来逼近恒等映射。如果恒等映射是最优的，那么通过残差学习重构，求解器可以轻松地使多层非线性层的权值趋向零来逼近恒等映射。<br>  虽然在实际情况中恒等映射不可能是最优的，但我们的重构将有助于对问题进行预处理。如果最优函数比起零映射而言更接近恒等映射的话，那么对于求解器来说，寻找关于恒等映射的扰动比学习一个新的函数要容易的多。我们通过实验验证（图7），学习到的残差函数通常只有很小的响应，这表明恒等映射提供了合理的预处理。</p><p>3.2 用快捷连接实现恒等映射<br>  我们对每一层堆叠层上采用残差学习。一个构造块在图2所示，在本文中，构造块的定义如下：</p><p>y = F(x,{W_i}) +x （1）</p><p>  其中x和y分别表示构造块的输入和输出向量。函数F(x,{W_i})表示需要学习的残差映射。图2中的示例有两层，F=W_2 σ(W_1 x)中的σ表示RELU，出于简化考虑省略了偏置项。操作F+x是由一个快捷连接和逐元素相加完成。在加法完成后再进行一次非线性操作。<br>  公式1中的快捷连接既没有引入额外的参数，也没有增加计算复杂度。这不仅是在实际应用中具有吸引力，而且在我们对比普通网络和残差网络时也尤为重要。这样我们可以在参数、深度、宽度以及计算成本都相同的基础上对两个网络进行公平的比较（除了可以忽略不计的逐元素加法）<br>  公式1中x和F的维度必须相同，如果不相同的话（比如当改变输入输出的通道数时），我们可以通过快捷连接做一次线性映射W_s来匹配两者的维度：</p><p>y = F(x,{W_i})+W_s x （2）</p><p>  我们同样可以在公式1中使用方阵W_s。但我们的实验表明，恒等映射足以解决退化问题，并且是一种经济的方式。因此W_s仅仅被用来匹配维度。<br>  残差函数F的形式是灵活的，虽然更多层也是可以的，但本文实验中涉及的F为2层或3层的（图5）。但如果F只有一层的话，公式1就会近似于一个线性层：y=W_1 x+x，对于这种情况，我们没看到它有什么优势。<br>  我们还发现，尽管上述的公式为了简便起见，都是关于全连接层的，但是它们同样适用于卷积层。函数F(x,{W_i})可以代表多个卷积层。在两个特征图的按通道顺序执行逐元素相加。</p><p>3.3 网络结构<br>  我们测试过多种普通/残差网络，并观察到一致的现象。我们在下文描述（用于ImageNet的）两个模型来进行讨论。<br>  普通网络：<br>  我们的普通网络（图3中）主要受VGG网络（图3左）的启发。卷积层的滤波器大多为3x3，并遵循了两个设计原则：<br>  1输出特征尺寸相同的层，含有相同数量的滤波器；<br>  2如果特征尺寸减半，则滤波器的数量必须翻倍，以保持每层的时间复杂度相同。<br>  我们直接通过步长为2的卷积层进行下采样。网络末端以一个全局的均值池化层和一个1000路的全连接层（Softmax激活）结束，有。加权层的总计34层，如图3所示。值得注意的是，比起VGG网络，我们的模型包含更少的滤波器和更低的复杂度。我们的34层结构含有36亿个FLOPS（乘法-加法），仅仅是VGG-19（196亿FLOPs）的18%。</p><p>残差网络：<br>  在普通网络的基础上，我们插入了快捷连接（图3，右），将网络转化为其对应的残差版本。当输入输出维度相同时，快捷连接可直接使用（公式（1））（图3中的实线）。当维度增加时（图3中的虚线所示的快捷连接），我们考虑两种策略：<br>  （a）快捷连接仍然使用恒等映射，增加的维度用零填充处理。此方法不会引入额外的参数；<br>  （b）通过公式2中的投影快捷连接来匹配维度（通过1×1的卷积核完成）。对于这两种选项，当快捷连接跨越两种尺寸的特征图时，均使用步长为2的卷积处理。</p><p>3.4 实现<br>  我们用于ImageNet的网络是根据]21,41]来实现的，图片根据短边等比缩放，短边长度在[256,480]区间内随机采样进行尺度增强[40]。从一张图像或者它的水平翻转图像中随机采样一个224x224的裁切，每个像素都要减去均值[21]。图像使用标准的颜色增强。我们在每一层卷积层之后，激活层之前采用了批量归一化（BN）。我们根据[13]中方法来初始化权重并对普通/残差网络从零开始训练。我们使用SGD算法，mini-batch的大小为256。学习速率从0.1开始，当错误率平稳时将学习速率除以10，对各模型进行了多达60万次迭代训练。我们将权值衰减设置为0.0001，动量设置为0.9。我们不用dropout，根据[16]的实验结果，我们没有使用Dropout。<br>  测试时，为了进行比较，我们采用了标准的十折验证。为达到最佳效果，我们采用了[40,13]中的全卷积形式，并在多个尺度的结果上取平均分。的网络就像中说的一样，最终结果为对多个尺寸图像（调整图像大小使得短边分别为{224,256,384,480,640}）</p><center>4 实验</center><p>4.1 ImageNet分类<br>  我们在ImageNet 2012分类数据集上评估了我们的方案。训练集包含1000中类别。训练集为128万张图片，验证集为5万张图片。并在测试服务器上的10万张图片上得到最终的测试结果。并对前1类和前5类错误率进行评估。<br>  普通网络<br>  我们首先评估了18层和34层普通网络。34层网络如图3（中）所示，18层普通网络结构相似。详细结构参见表1。<br>  表2中的结果表明较深的34层普通网络比较浅的18层普通网络有着更高的验证误差。为了揭示这种现象的原因，在图4中我们比较了它们在训练过程中的训练误差和验证误差。从图中我们观测到了明显的退化问题：34层的普通网络在整个训练过程中有着较高的训练误差，尽管18层普通网络的解空间只是34层普通网络的一个子空间。<br>  我们认为这种优化难题不可能是由梯度消失导致的。因为这些普通网络在训练时使用了批量归一化，这能保证前向传递的信号具有非零方差。我们同样验证了反向传递阶段的梯度由于批量归一化而具有良好的范式。所以前向和反向阶段的信号都不存在消失的问题。事实上34层的普通网络仍然有不错的准确率(表 3)，这表明了求解器在某种程度上是有效的。我们推测，深层普通网络的收敛率是呈指数衰减的，这影响了训练误差的降低。这种优化困难的原因我们将在以后的工作中进行研究。<br>  残差网络<br>  接下来我们对18层和34层的残差网络进行评估。残差网络的基本框架和普通网络基本相同，除了在每一对3*3的滤波器间添加了一个快捷连接，如图.3 (右)所示。在表2以及图.4(右)的比较中，所有的快捷连接都是恒等映射，并对维度增加采用零填充(选项A)。因此，比起普通网络，它们并没有增加额外的参数。<br>  我们从表2和图4中得到了三个重要发现。<br>  第一，与普通网络相反，34层的残差网络要优于18层残差网络(提高了2.8%)。更重要的是，34 层的残差网络在训练集和验证集上均表现出相当低的误差。这表明这种设置可以很好地解决退化问题，并且我们可以由增加的深度来提高准确率。<br>  第二，与对应的普通网络相比，34层的残差网络在top-1 误差上降低了3.5% (表2)，这得益于训练误差的降低(图.4右vs左)。这也验证了残差学习在极深网络中的有效性。<br>  最后，我们同样注意到，18层的普通网络和残差网络的准确率很接近 (表2)，但是18层的残差网络收敛速度更快(图4右vs左)。 如果网络“并不是特别深” (如18层)，现有的SGD依然能够对普通网络求的不错的解。在这种情况下，残差网络能够使优化得到更快地收敛。</p><p>  恒等 vs 映射快捷连接<br>  我们已经验证了无参数的恒等快捷连接是有助于训练的。接下来我们研究了映射快捷连接(公式2)。在表3中，我们比较了三种选项：<br>  (A) 对增加的维度使用零填充，所有的快捷连接都是无参数的(与表2 和 图4 (右)相同)；<br>  (B) 对增加的维度使用映射快捷连接，其它使用恒等快捷连接；<br>  (C) 所有的都是映射快捷连接。<br>  表3表明这三种选项都比没有快捷连接要好。B略好于A，我们认为这是因为A中使用零填充的维度并没有进行残差学习。C略好于B，我们把这个归结于多个（13个）映射快捷连接引入了众多的额外参数。不过A、B、C之间细小的差别也表明了映射连接方式对于解决退化问题来说并不是必不可缺的。所以我们在本文接下来的内容中，为了减少空间和时间复杂度以及模型尺寸，并没有使用选项C的模型。恒等映射因其没有引入额外的复杂度而对以下介绍的瓶颈结构尤为重要。</p><p>  深度瓶颈结构<br>  接下来我们介绍用于ImangeNet的更深的模型。考虑到训练时间的限制，我们将结构快修改成瓶颈结构设计。对于每一个残差函数F，我们使用了三层堆叠层而非两个(图5)。 这三层分别是1<em>1、3</em>3 和1<em>1 的卷积层。1</em>1 的层主要负责减少然后增加（恢复）维度，使得3*3的层有更小的输入和输出维度。图5展示了一个例子，这两种设计具有相似的时间复杂度。<br>  无参数的恒等快捷连接对于瓶颈结构尤为重要。如果使用映射快捷连接来替代图5(右)中的恒等快捷连接，将会发现时间复杂度和模型尺寸都会加倍，因为快捷连接连接了两个高维端，所以恒等快捷连接对于瓶颈设计是更加有效的。</p><p>  50层ResNet<br>  我们将34层网络中2层的结构块替换成3层的瓶颈结构块，得到了50层ResNet (表 1)。使用选项B来处理增加的维度。整个模型含有38亿个FLOPs。</p><p>  101层和152层 ResNets<br>  我们使用更多的3层模块来构建101层和152层的ResNets (表1)。值得注意的是，虽然层的深度明显增加，但是152层ResNet的复杂度(113亿个FLOPs)仍然比VGG-16(153 亿个FLOPs)和VGG-19(196亿个FLOPs）的小很多。<br>  50/101/152层ResNets比34层ResNet的准确率要高得多(表3和4)。而且我们并没有观察到退化问题，并从增加的深度中得到了显著提高的准确率。所有的指标都证明深度带来了好处。(表3 和4)。<br>  与前沿方法的比较<br>  在表4中我们与目前最好的单模型结果做了比较。我们的34层ResNets取得了非常好的准确率。152层的ResNet的单模型top-5验证误差仅为 4.49%，甚至比先前组合模型的结果还要好 (表5)。我们将6个不同深度的ResNets合成一个组合模型(在提交结果时只用到2个152层的模型)。这在测试集上的top-5误差仅为3.57% (表5)，这一项在ILSVRC 2015 上获得了第一名的成绩。</p><p>4.2 CIFAR-10 与分析<br>  我们在包含5万张训练图像和1万张测试图像的10类CIFAR-10数据集上进行了更多的研究。我们在训练集上进行训练，在测试集上进行评估。我们关注的是极深模型的效果，而不是追求最好的结果，因此我们特意使用了如下的简单框架。<br>  普通网络和残差网络的框架如图3(中/右)所示。网络的输入是32<em>32的减掉各像素均值的图像。第一层是3</em>3的卷积层。然后我们使用6n个3*3的卷积层的堆叠，卷积层对应的特征图尺寸有三种：{32,16,8}，每一种卷积层的数量为2n 个。对应的滤波器数量分别为{16,32,64}。使用步长为2的卷积层进行下采样。在网络的最后是一个全局的平均池化层和一个10类的包含softmax的全连接层。一共有6n+2个堆叠的加权层。具体的结构见下表：</p><p>  使用快捷连接来连接3<em>3的卷积层对(共有 3n个快捷连接)。在这个数据集上我们所有的模型都使用恒等快捷连接(选项 A)，因此我们的残差模型和对应的普通模型具有相同的深度、宽度和参数量。<br>  我们将权值衰减设置为0.0001，动量设置为0.9，采用[13]中的权值初始化和批量归一化[16]，并且没有使用dropout。模型的mini-batch的大小为128，在2块GPU 上进行训练。学习率初始为0.1，在第32000和48000次迭代时将其除以10，总的迭代次数为64000，训练集/验证集划分为45000/5000。我们在训练阶段遵循[24]中的简单数据增强法则：在图像的每条边填充4个像素，然后在填充后的图像或者它的水平翻转图像上随机采样一个32</em>32 的裁剪。在测试阶段，我们只使用原始32*32的图像进行评估。<br>  我们比较了n={3,5,7,9}的情况，也就是20、32、44以及56层的网络。图6(左) 展示了普通网络的结果。深度普通网络随着层数的加深，训练误差也在变大。这个现象与在ImageNet(图4, 左)和MNIST（见[42]）上的结果很相似，这表明了优化困难确实是一个很基础的问题。<br>  图6(中)展示了ResNets的效果。同样与ImageNet的情况(图4, 右)类似，我们的ResNets能够很好的克服优化难题，并且随着深度加深，准确率也得到了提升。<br>  我们进一步探索了n=18，也就是110层的ResNet。在本例中，我们发现0.1的初始学习率有点太大以至于不能很好地开始收敛。所以我们刚开始使用0.01的学习率，当训练错误率在80%以下(大约400次迭代)之后，再将学习率调回0.1继续训练。剩余的学习和之前的一致。110层的ResNets收敛得很好 (图6, 中)。它与其它的深层窄模型，如FitNet和 Highway (表6)相比，具有更少的参数，然而却达到了最好的结果 (6.43%, 表6)。</p><p>  层响应分析。<br>  图7展示了层响应的标准差(std)。响应是每一个3*3卷积层的BN之后、非线性层(ReLU/addition)之前的输出。对于ResNets，这个分析结果揭示了残差函数的响应强度。图7表明了ResNets的响应总体要比它对应的普通网络的响应要小。这些结果也验证了我们的基本动机(章节3.1)，即残差函数比非残差函数更接近零。从图7中ResNet-20、56和110的结果，我们也注意到，越深的ResNet的响应幅度越小。当使用更多层是，ResNets中单个层对信号的改变越少。<br>  探究1000 层<br>  我们探索了一个超过1000层的极深模型。我们设置n=200，也就是1202层的网络模型，并按照上述方式进行训练。我们的方法对1000层的模型也并不难优化，并且达到了&lt;0.1%的训练误差(图6,右)，它的测试误差也相当低(7.93%, 表 6)。<br>  但是在这样一个极其深的模型上，仍然存在很多问题。1202层模型的测试结果比110层的结果要差，尽管它们的训练误差差不多。我们认为这是由过拟合导致的。这样一个1202层的模型对于小的数据集来说太大了(19.4M)。在这个数据集上强正则化方法，如maxout或者 dropout，才能获得最好的结果。在本文中，我们并没有使用maxout/dropout，只是简单的通过设计深层窄模型来进行正则化，因为我们关心的是优化难题。但是通过强大的正则化或许能够提高实验结果，我们会在以后进行研究。</p><p>4.3 PASCAL和MS COCO上的物体检测<br>  我们的方法在其它识别任务上展现出了良好的泛化能力。表7和8展示了在PASCAL VOC 2007 和 2012以及 COCO上的目标检测结果。我们使用快速R-CNN作为检测方法。在这里，我们比较关注由ResNet-101 替换VGG-16所带来的提升。两种模型进行检测时的具体实现是相同的。所以检测结果提升只能来自更好的网络。最值得注意的是，在COCO数据集上，我们在COCO的标准指标(mAP@[.5, .95])上比先前的结果提升了6.0%，这相当于28%的相对提升。而这完全得益于所学到的表达。<br>  基于深度残差网络，我们在ILSVRC &amp; COCO 2015竞赛的ImageNet检测、ImageNet定位、COCO检测以及COCO分割上获得了第一名。</p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>二十分钟带你读完《中国历代政治得失》</title>
      <link href="/2018/03/03/%E4%BA%8C%E5%8D%81%E5%88%86%E9%92%9F%E5%B8%A6%E4%BD%A0%E8%AF%BB%E5%AE%8C%E3%80%8A%E4%B8%AD%E5%9B%BD%E5%8E%86%E4%BB%A3%E6%94%BF%E6%B2%BB%E5%BE%97%E5%A4%B1%E3%80%8B/"/>
      <url>/2018/03/03/%E4%BA%8C%E5%8D%81%E5%88%86%E9%92%9F%E5%B8%A6%E4%BD%A0%E8%AF%BB%E5%AE%8C%E3%80%8A%E4%B8%AD%E5%9B%BD%E5%8E%86%E4%BB%A3%E6%94%BF%E6%B2%BB%E5%BE%97%E5%A4%B1%E3%80%8B/</url>
      
        <content type="html"><![CDATA[<p>这本书我断断续续读了好久。 一开始是因为书中内容太多，看了后面的总是忘掉前面的，于是静下心来做起了阅读笔记。总共一万三千多字，大多数都是书中文字，我自己加以提炼和组合。 <a id="more"></a>​ ## 汉代 ## ### 1.汉代政府组织 ###</p><p>秦以后，中国开始有了统一的政府，皇位世袭在钱穆看来，是一种自然而且不得已的做法（因为人口众多，地域辽阔）。其实这已经是相当大的进步了。封建时代众多贵族都有世袭特权，但秦汉以后，封建制度被推翻，单只有皇室一家能世袭。</p><p>化家为国后，原来天子家里各个管事之人演变成了中央政府组织，以宰相为例，在古代，祭祀乃贵族家庭里最重要的事，而祭祀时最重要的事在宰杀牲牛，当时替诸侯乃及一切贵族公卿管家的都称为“宰”。秦汉统一后，一切贵族家庭都倒下了，只剩一个家便成了“国家”，而他家里的家宰，也就变成了掌管国家的政治领袖。三公中，要数宰相为最高行政长官，九卿虽照名义来历，本应是皇帝的家务官，但化家为国后，家务转变为政务，九卿其实全都隶属于宰相。</p><p>钱穆先生认为“两汉吏治”永为后世称美，汉代地方太守地位与中央九卿平等，故汉代官级分得少，升转灵活。虽然地方行政区划分的比较小，但却不觉得中央政府高高在上。</p><h3 id="汉代选举制度">2.汉代选举制度</h3><p>汉武帝之前，朝廷官员推举其子侄后辈进宫当侍卫，遇政府需要人，再从中挑选分发。故这一制度虽非贵族世袭，但仕途仍为贵族团体垄断。汉武帝之后，设立太学，经太学毕业考试，甲等为郎，乙等为吏，一定程度上扩展了入仕的途径。</p><p>汉代选举制度大体上分三种。一种是无定期的，凡遇新帝即位，天灾人祸，政府都要下诏希望地方推举贤人，来为国家做事。这也是“策问”“对策”的由来。第二种是特殊选举，针对一些特殊任务，如出使西域、治水、用兵，凡有此类方面之才的人，可以由别人推荐，也可自己应选。第三种就是举孝廉，由于地方不积极，应选人不踊跃，汉武帝曾下诏，认为这是地方长官的失职。在此之后，无形中就形成了每郡每年必须推选出一到两个孝廉的传统。但全国有几百个郡，久而久之孝廉太多，郎署充斥，前两种选举形式都无形中被搁置了，仕途只剩下孝廉察举这一条路。后来，孝廉只是参政资格的名称，地方察举之后，中央还要加上一番考试，于是整个朝廷几乎都是读书人，渐渐形成了崇尚文治的政府。</p><h3 id="汉代经济制度">3.汉代经济制度</h3><p>汉代算是做到了“轻徭薄税”，大概只要三十税一，甚至在文帝时，曾有十一年之久免收田租，盖因中国疆土广、户籍盛，赋税尽轻，但供养一个政府还是用不完的。但农民的日子并没有好过多少，因为在汉代，封建时代的井田制早已废弃，土地为农民私有，可以自由使用也可自由买卖。卖掉土地之后，农民就成了佃农，而地主对佃农的租额很高，因此政府减轻田租实际上是便宜了地主。封建时代的贵族是政治性的，而此刻的地主确实由经济条件形成的。</p><p>原本田赋由政府所有，商税占小部分，由皇室所有。但山林池泽的商税在盐铁之利逐渐膨胀之后，逐步超过了全国田租。汉武帝常年征战，花钱如流水，花光了政府的钱和祖辈积蓄后，不得不自掏腰包，即把少府的钱拿出来。又号召全国的有钱人，主要是盐铁商，也来捐助，但反响不大，于是武帝很不爽，便收归全国的山海池泽等一切非耕地为国有，由政府来经营，这便是“盐铁政策”。</p><h3 id="汉代兵役制度">4.汉代兵役制度</h3><p>概括而言有全国皆兵的特点，国民除了服兵役之外，还要服力役，即义务劳动。比较不合理的地方在于，每个国民还需要缴纳人口税，在没有生活保障的前提下，这样做无异于耍流氓。也因此，不少穷人为了避免缴纳人口税，宁愿去富人家里做奴隶，因为奴隶的人口税由奴隶主代缴。与以往做奴隶不同的是，这并非出卖自由，而是出卖对国家法规上的应尽的职责。奴隶主也没有因此吃亏，因为入山烧炭、开矿都需要大量的劳动力。</p><h3 id="汉制得失检讨">5.汉制得失检讨</h3><p>经济制度上没有解决土地问题，形成兼并，富者田连阡陌，穷者无立锥之地，使政府的减轻租税政策失效。</p><p>军队制度，犯了形式主义的错误，人少，时间短，训练简略，虽全国皆兵，却有名无实。</p><p>政府组织，虽然皇权和相权是分开的，但中国一向看重不成文法，没有明确的制度来规范皇权，遇上好的皇帝，如汉武帝雄才大略，事情也做得好，皇帝坏了，而政治上并没有管束皇帝的制度。这就导致了后来皇戚霍光独掌大权，切断了内廷与外朝的联系。</p><p>选举制度也有问题。孝廉充斥仕途，阻塞了其他入仕之路，人人争要为孝廉，孝廉也就变了质。地方长官若贤良，则选拔真才；若长官营私舞弊，则推选私人。此外，汉代选举，要先进学校读书，才获补吏，补吏以后，才获察举。看似合理，但在古代社会，读书机会不易得。那时印刷术还未出现，书籍都用竹帛书写，这对读书求学有极大的限制。虽然爵位不能世袭，但书本可以世袭，由此便可世代进入政治圈子，世代为官。有言："黄金满籯，不如遗子一经"，说的便是一本书的资本价值，胜过了一筐黄金的资本价值。官官相互照顾，由是便形成了“门第社会”，这是一种变相的世袭特权。所以要说中国魏晋以下的门第社会之起因，主要要追溯到汉代察举制度。</p><p>总的来说，汉代制度还是有进步的，至少他们懂得皇权之外有相权，懂得政府用人的客观标准不是血统的亲属，而是能力的大小。</p><h2 id="唐代">唐代</h2><h3 id="唐代政府组织">1.唐代政府组织</h3><p>在汉代，宰相一人掌握全国行政权力；而唐代则把相权分别操掌于几个部门，凡事经各部门商议而定。具体来说，即中书省、门下省、尚书省等于汉代一个宰相。</p><p>“宰”和“相”在春秋时代仅系封建贵族的家臣，到了秦汉则化私为公，变成政府的执政官。东汉以后魏晋南北朝时代，皇帝将其私属如中书、门下、尚书之类的来代行政府宰相的职权。到了唐代，正式把宰相的职权分配给三省。</p><p>三省的职能：中书省负责拟撰诏书，即为“敕”，呈送皇帝画敕然后行达门下省。门下省行审查之职，如若反对此诏书，即将原诏书批注送还，称为“涂归”。诏敕自中书定旨、门下复审手续完成后，即送尚书省执行。尚书省只有执行命令之权。</p><p>关于中书省，有一个比较有趣的观点：钱穆讲，中国政治上的传统观念，对一意见之从违抉择，往往不取决于多数，而是取决于贤人，即哪一人贤，就采取哪一人的意见。这就解释了为什么汉代的选举权是由地方长官行使，而非一般民众。说回中书省，由七八个中书舍人拟稿，是谓“五花判事”。然后再由中书令或中书侍郎就许多初稿选定一稿，稍加补充修润，称为正式诏书。</p><p>可以看出这种制度的麻烦之处在于，一旦门下省驳回诏书，则此道命令等于白费，皇帝的画敕为无效。为了避免这种情况的出现，如遇下诏敕，便先由中书省和门下省举行会议，两省相关长官皆出席，会议场所称为“政事堂”。但尚书省长官不出席，故在唐人眼中，中书门下才是真宰相。</p><p>一个有趣的地方是，唐太宗即位前曾做过尚书令，及太宗即位，朝中无臣敢再当尚书令之职，因此尚书令常虚悬空缺，仅有两个副长官，即尚书左仆射和右仆射。</p><p>皇帝的命令如若未加盖中书、门下之印，直接由皇帝发出，在当时是违法的。故说“不经凤阁鸾台，何名为敕。”（武则天改称中书省为“凤阁”、门下省为“鸾台”）。不过中国传统政治有一种通融性，每一制度都有变通的余地。说上面那句话的刘炜就被武则天杀了……武则天以下的唐中宗虽也会不经两省径自封拜官职，但究竟心怯，装诏敕的封袋改用斜封，所书“敕”字也由朱笔改为墨笔，时称“斜封墨敕”。而被斜封的官职也为一般人看不起。因此，不是说中国传统没有法制，只是有时不严格遵守。</p><p>说了半天，那唐代的宰相哪去了？毕竟废除宰相制可是在明朝。政事堂开会时，有一主席，称为“执笔”，相当于书记长，由他记录大家的意见，并最后形成文字决定。所以唐代宰相一职，由这样一个“首席”来代替。</p><p>尚书省共分六部，相比于汉代九卿，可谓是一大进步。因为汉代九卿单从官职的名称上讲，都摆脱不了宫廷私职的味道。而唐代则是正式将这些官名确定为政务官。如九卿中的光禄勋正名为“吏部”，卫尉正名为“兵部”。无论从体制上还是从观念上讲，都大大进步了。</p><p>再要说说《唐六典》，这是和《周礼》齐名的中国政治制度方面的两大著作。客观记载了唐代的实际行政法规，是中国历史上行政法规之巨典。后朝大都以此为典范，无多变更。</p><p>虽然唐代的中央政府较汉代有进步，但以地方政府论，则唐似不如汉。究其原因在于，唐代地方官与中央官并非平级（汉代太守和九卿位同），而地方官有分出了更多的等级。升了几级，还像没有升一样。下级轻易不会迁升到上级，对行政实际效力影响极大。</p><p>在中央，除了三省六部外，还有一台，即御史台，似由汉代御史大夫演变而来，主管监察。派往地方监察的御史，称为“观察使”。糟糕的是，观察使较之地方行政长官而言，级别更高，权力更大，逐步演变成地方最高长官。这无疑加强了中央集权。</p><p>如若监察使巡视边疆，则被称为“节度使”。“节”是当时一种全权印信，有此者便可全权调度，故称“节度使”。节度使在地方指挥军事，管理财政，甚至是用人大权，于是便形成了“藩镇”。原本想中央集权，却变成了藩镇割据，反抗中央。安史之乱即由此产生。</p><h3 id="唐代考试制度">2唐代考试制度</h3><p>之前讲汉代的选举制度，没有客观的用人标准，全靠地方长官举贤，后期就逐渐演变成拥护门第的制度，将入仕的范围缩小到门第的小范围内。唐代针对此弊，改为自由竞选，把进仕之门扩大打开，各人到地方政府报名，参加中央考试。</p><p>大体上讲，较之前是进步的，不过后来还是毛病百出。比如，对报考没有限制，于是报考之人无限增加，求官者多，得官者少，政府不得不对录取名额逐步放宽，类似于现在的扩招。所谓“士十于官，求官者十于士，士无官，官乏禄，而吏扰人”。这是政权开放的流弊。</p><p>政府要中央集权，鼓励做官，压制工商业（在唐代，工人和商人是不能报考的）全社会的聪明才智之人都跑去做官，仕途充斥，造成了政治上的臃肿病。</p><h3 id="唐代经济制度">3唐代经济制度</h3><p>唐代的田赋制度称为“租庸调”，租即征粮，庸即征役，调即征布帛。其中租是分配给人民耕地，年老归还政府，授田期间负担租额。因此这是一种“均田”制度，不同于井田制度，井田属于封建贵族，均田属于中央政府。无论是从租额还是服役时间来看，都较汉代有所减轻。</p><p>而租庸调之所以能推行，依靠的是账籍制度。“籍”是户口册，“账”是壮丁册子。壮丁册子一年重造一次，户籍册子三年重造一次，县、州、户部都要保存。对于这样大的一个国家，普遍的调查、登记、改动、校对十分麻烦，这须有一种精神力量来维持，否则很难历久不衰。官员的偷懒马虎是租庸调制度失败的最大原因。因此，账籍制度的推进和继续须有与之相当的道德意志与服务忠诚，否则纵然法良意美，终是徒然。</p><p>后来租庸调制度崩溃后，取而代之的是“两税制”。因其一年分夏秋两次收税，故称“两税”。与租庸调制度最显著的不同在于，两税制是“户无主客，以见居为簿”，意思就是不管你是哪儿的人，只要住在一个地方就加入这地方的户口册。如是则人口迁徙较为自由了。又说“人无丁中，以贫富为差“，这是说你有多少田，政府便向你受多少租。如是则义务劳动等种种负担也获得解放了。上述可以说是两税制的好处，然而政府不再授田，民间自由兼并，这将中国传统一贯的平均地权、还授田亩的做法打破了。直到清代，都是容许田亩自由买卖兼并的。</p><p>汉唐经济财政之比较：汉代自汉武帝创行盐铁政策，是为了“节制资本”，不让民间过富，虽然轻徭薄赋，但人民并没有得到实际的好处，倒是中间地主阶层占了便宜。唐代的租庸调制度不仅在于轻徭薄赋，尤其侧重为民制产，每一穷人，政府都设法授田，保障其基本生活。简单说，汉代是在社会上层节制资本，而下层则没有力量管；唐代注意社会下层，允许你过富，但不让你过穷。</p><h3 id="唐代兵役制度">4.唐代兵役制度</h3><p>汉代可以说是“全农皆兵”，将国防武装寄托于农民的生产集团，结果搞得有名无实。唐代沿袭了北周苏绰所创立的制度，即“寓农于民”，亦即是“全兵皆农”，每个军人都要种田，但并不是每个人都要当兵。这种制度在当时称为“府兵”。府指的是军队屯扎地，当时将户口分为九等，下三等民户没有当兵的资格，只有上等和中等中的人在自愿的情况，再由政府选拔才能当兵。当兵人家的租庸调豁免，但军人并无饷给。</p><p>所以这个政策精明的地方在于，国家不用花一文钱、一粒米来给养军队，因为他们有田有地，一面保卫国家，一面还自力生产。</p><p>唐朝文官分品级，武官分勋阶。勋爵对于武官优待来自国家社会，有时是经济的，有时是名誉的。但有勋无职，并不干预政治。</p><p>后来府兵制度还是失败了，原因是人事颓废。</p><p>第一，一开始到中央政府轮值的宿卫受到政府重视，当兵的自己也觉得光荣。后来天下太平，每年几万人轮值中央却没什么事可做，政府也不重视了，倒是沦为了权臣亲贵的苦力，干些造宅第盖花园的苦工，受人轻视，渐渐就没人愿意上番值宿了。</p><p>第二，唐初对待阵亡将士的抚恤工作做得还是很及时到位的，后来军队和政府怠慢，死者家属见不到抚恤慰问，人似乎是白死了，渐渐失去了人心。</p><p>此外，有了相当勋位的军人有的只是荣誉，不是实职官员，说到底还是一个兵，有时还要服力役，给差唤，因此勋位在身，不为荣反为辱。后来政府可以开边，需要防戍边疆的军队，新的兵送不出去，旧的想复员也复不成，甚至有边疆的营官故意想搞死你拿你的带去的财物，唐代的府兵制度就垮了台。</p><p>后方兵力枯竭，政府有钱有势，临时买外国人当兵。安禄山、史思明这些中国边疆大吏实际上都是外国人。唐代太富太强，疏忽了民族界线，大量用外国人当兵做将，，结果才弄得不可收拾。</p><p>​</p><p>​</p><h2 id="宋代">宋代</h2><h3 id="宋代政府组织">1.宋代政府组织</h3><p>开篇钱穆就将宋代评价为汉、唐、宋、明、清五个朝代中最贫最弱的一环。</p><p>首先是相权被分割。</p><p>虽然宋代也有三省，但门下、尚书省都移到了皇宫外，故只有中书省单独取旨，称“政事堂”。晚唐五代又传下来一个新机构。叫“枢密院”，主管军事。中书为丞相，然中书和枢密对立，因而宰相管不着军事。</p><p>宰相被剥夺的还有财政权（另设三司理财）、用人权（另设考课院）。如是，形成了中书治民、枢密主兵、三司理财的军、民、财职权三分的局面。</p><p>然后是君权之侵揽。</p><p>从上述的三权分割就能看出相权的低落，那与之相反的即时君权的提升。一方面是由五代乱世造成的局面。宋太祖本是后周的一个“殿前都检点”，类似一个皇帝的侍卫长，因缘际会，一夜之间成了皇帝。然而像他这样黄袍加身做皇帝的，到他已经是第四个了。于是，在那个黑暗的时代，宰相有做一二十年的，而皇帝却经常换来换去。皇帝实在是太不像样了，其他一切官，都会连带不像样。现在要拨乱反正，尊王是第一步。</p><p>以往朝代，宰相上朝得有座位，并赐茶。到宋代时，宰相就一同站着不坐了。还有诏书。在唐代本是由中书省拟定，然后送呈皇帝朱批，是谓“熟拟”和“印画”。通俗地讲，皇帝在政府所下的一切最高命令，有他的同意权。到了宋代，为推尊皇帝，遇政府定旨出命，先写一“劄子”，这是一种意见的摘要，对某事提出几项意见，拟成几条办法，送由皇帝决定，是谓“面取进止”。然后宰相再按皇帝的意见正式拟旨。如此一来，皇帝不仅有同意权，还有了参加意见的权利，而宰相不过是奉命行事，所以君权重了，相权轻了。</p><p>再说宋代地方政府。</p><p>宋太祖杯酒释兵权后，武臣不再带兵，自然也不再管地方民政。他们仅拥一官名，中央把他们留在首都供养着。好比你是江苏督军，中央还保留你江苏督军的名衔，但请你在中央住着，至于江苏的事，另派一位文官去，这就叫“知某州事”、“知某府事”（路，府、州、军、监，县是宋代的地方行政单位）。这也是后来知县、知府等官名的由来。</p><p>在唐代，中央派到地方考察行政的叫“观察使”，在宋代又称“监司官”，每一路共有四个监司官，有不同的职能。坏处就是地方长官要奉承四位上司，可想而知着地方官有多难做。</p><p>再有就是宋代的中央集权进一步增强，体现在军权、财权的集中。地方的全部财富都转运中央，地方则日趋贫弱。所以中央一败，全国就土崩瓦解。</p><h3 id="宋代考试制度">2.宋代考试制度</h3><p>宋代考试制度大体沿袭唐代，在此简略说明其缺点。</p><p>一是有考试但无教育。两汉有太学，唐代有门第，经过教育的人比较懂得政治掌故，一旦从政也比较有办法。而到了晚唐，大门第逐步堕落，应考的多数是寒窗苦读的穷书生，他们除了对留心应考的科目外，对政治传统则茫然无知，就算是进入仕途，对实际政治不免生疏。</p><p>二是考试内容改变。不考诗赋，该考经义。最初的想法是，人人学诗赋，风花雪月，这样选人才的办法终不妥当。但改革后却发现得不偿失，王安石因此叹息说：“本欲变学究为秀才，不料转变秀才为学究。”</p><h3 id="宋代兵役制度与国防弱点">3.宋代兵役制度与国防弱点</h3><p>钱穆将宋代兵役制度评为中国历史上最坏的兵役制度，但也是有缘由的，不能过分苛责。</p><p>唐末五代时，藩镇骄横，兵乱频仍，几乎人人都当兵，快要没了读书人。单反当兵的，脸上都要刺字，称为“配军”，防止逃跑。这就解释了《水浒传》里的刺配。宋代军队分两种，一种是禁军，留在中央，一种是厢军，留在地方。“厢”是城厢之意。</p><p>照理，宋代开国后应当裁兵复员，但只是按照划分禁军厢军这样裁了，至于复员，不存在的。因为宋代虽得了天下，但并未能统一中国，如辽、西夏。</p><p>有趣的是，宋代定都开封，这是一个没办法守的地方。开封是一片平地，又处在黄河边上，骑兵从北南下，三天就能到黄河边，一渡黄河，就到了开封城下。相比之下，洛阳和长安都有险可守。但之所以选择开封，是因为宋代国防线早已残破，宋太祖不得不养兵，而养兵要粮食。当时的军粮全靠长江流域供给。由扬州沿通济渠可以西达开封，若是再运往洛阳就要靠陆运，浪费许多人力物力。宋代开国，承接五代长期黑暗残破的局面，实在没有多余的力量。所以定都开封是无奈之举。</p><p>但宋朝不敢和辽国开战，因为要打就必须赢，败了一退就到黄河边，国本就动摇了。所以不能打仗，却又不得不养兵。养了兵又不看重他们，宋代刻意提倡文治，倒是扭转了晚唐五代一段中国历史逆流。宋太祖曾留下遗嘱：不杀士大夫。他的后人牢记此家训，直到南宋还是守着该遗训。岂止不杀，实在是优待，这也是从唐末五代混乱黑暗的局面下文化能慢慢复兴的原因。</p><p>其次是国防资源问题。北方多是平原，所以在塞外作战，一定要骑兵才行。而骑兵所需的马匹在中国只有两个地方出产。一个在东北，热察一带，一个在西北，甘凉河套一带。（都是高寒之地，有山谷甘泉美草旷地）这样的地方才能养好马。而这两个地方在宋国开国时，一个被辽东拿走，一个被西夏拿走。中国内地不方便养马，养出来的也不是好马。</p><p>所以说宋代是拿了一手烂牌，也没有打好。防御性的国防迟早要失败，不过重视读书人，文治复兴，内部也没出什么大毛病。</p><p>​</p><p>​</p><h2 id="明代">明代</h2><h3 id="明代政府组织">1.明代政府组织</h3><p>钱穆讲，就政治制度来说，明代是大大退步的。</p><p>对于中国传统政治的专制、独裁等看法，用来讲明、清是可以的。</p><p>明太祖洪武十三年，因宰相胡维庸造反（有争议），明太祖从此废除宰相。</p><p>宋代时，门下省已经退处无权，当时的宰相其实就是中书省。到了明代，明太祖把中书省废去，只留下中书舍人。在唐代，中书舍人是代拟诏敕的，现在只是管理文书与抄写之职。中书、门下两省都废了，只剩尚书省，但尚书令和左右仆射也不设了，没了长官，改由六部分头负责。六部中的本司升为部长，六部首长，各不相属。</p><p>此外有“都察院”，由御史台变来的，专掌弹劾纠察。与六部并称“七卿”。</p><p>七卿之外，还加一个“通政司”，一个“大理院”，则称“九卿”。通政司管理全国中外一切奏章呈送皇帝，是一个公文出纳的总机关。大理院主平反，凡是判决不了的刑法案件，都可以到大理院求平反。刑部尚书加上都察院和大理院，又叫做“三法司”，是司法机关。朝廷的一切重大司法案件由三法司会审。</p><p>九卿之上，更无首长，所以明制是“有卿而无公”政府诸长官全成平列，上面总其成者是皇帝。</p><p>不过，虽说明代一切事权集中在皇帝，但终究还有历史旧传统，即不是由全由皇帝独裁。许多事，必经廷推（推举大官）、廷议（商议大事）、廷（解决大的狱讼）。此外，各部都有给事中，官阶虽小，但却重要。对于发到各部的命令，他们可以参加审核，发表意见，只要他们不同意，仍可原旨退还。这也是君权之一节限。</p><p>明代的内阁制度是特色。原因就是皇帝拦下大权后，一人管不尽这么多事，于是就需要一个秘书处来帮忙打理，即内阁。内阁的这些人就是“内阁大学士”。在太祖时，这些大学士类似于皇帝的顾问，遇皇帝不清楚的事，可以随时问他们作参考，政治大权还是在皇帝而非大学士。除了看奏章，明制一天有三次朝，称“早朝”、“午朝”、“晚朝”。除了见群臣还要见民众，是为“御殿”（在大殿内朝会议事）、“御门”（到奉天门的阳台上和老百姓见面讲话）。</p><p>说这些只是想说明明代的皇帝实在太忙。太祖和成祖都是亲手打下了天下，因此他们有精力做独裁的皇帝。在此之后的儿孙，都是生长在深宫中，没了那精力，便只有偷懒，把政权交付给内阁，内阁大学士就扮演起了宰相的角色，是为“首辅”。</p><p>而皇帝与内阁经常不见面，他们之间的接触就给了太监上下其手的机会。太监除了作为内阁和皇帝接触的媒介，甚至还帮皇帝批公事，“批红”的实权落到了太监手里，太监倒成了真皇帝，掌握政府一切最高最后的决定权。首辅若真想做点事，也必须先勾结太监。就连一代首辅张居正也只能结合太监，才能揽得实权。</p><p>但当时的朝臣大家都反对张居正，说他明明不是宰相，不是政府的行政首长，不该弄权专政。这话不错，因为当时，六部长官才是政府最高行政长官，他们只听命于皇帝，不听命于内阁。照法理讲，张居正是理亏的。后世不能总认为张居正是一大政治家，就认为他应该施展抱负，策动政事。毕竟按制度讲，张居正这样做违反了国家大法。本来皇帝该管的事，他来管，可不就非法了吗？</p><p>他一死，家就被抄了。</p><p>说这些，正是阐明了制度是如何牵制着人事。</p><p>再来讲讲明代地方政府。</p><p>讲明代地方行政，最先提到的就是所谓省区制度。而行省制度，是从元代开始的。在金、元两代，开始有“行中书省”。中书省是当时中央的宰相府，一般称为“都省”。行中书省是由中央宰相府分出的一个驻扎在外面的机关。这是因为蒙古人征服了中国，不敢把政权分散，要完全把握集中在中央。某地出了事，就由中央派一两个人去镇压，“行省”是一个行动的中书省。说到底，就是不放心把政权交给地方。着有点像过去英国在香港、印度设立的“总督”。元代是有中央无地方的，中国只是其征服地，像香港之于英国。</p><p>再深一层言之，这种行省设置，实际上不是为了行政方便，而是为了军事控制。明代人自然懂得这一制度的用意，现在元代没了，这一制度在名义上就说不通，而且明代已废了中书省，更何来行中书省？所以将行省长官改成“承宣布政使”，全国正式划分为十三“承宣布政使司”。就官制而言，地方区域，不该称为“司”，从内在精神来说，这个用意已经非常明显了。（还不懂？在本朝，省委领导都是中央调派，这下明白了吧？）至于清代，则又沿袭了“省”的称谓，而这一直是名不正，言不顺的。钱穆讲，省区的“省”字，根本就是个不祥的名称，最好以后能在新的地方政治区域之划分下把这字革除，再不沿袭。我查阅资料后得知，台湾目前的行政划分为2省6直辖市，先生想必也很失望。</p><p>再说明代地方长官。与承宣布政使（又叫藩司）并列的，还有提刑按察使（又叫臬司，管司法），都指挥使（管军事）。合称为“三司”。他们手底下又有官，这种官派出去叫做“分司”，到地方协助办事。这样一来，地方政府的事情就更不好办了。明制是这样的，从低到高为县——府、州——分司——司（省）。据记载，山东省有六个府，但有十六个分司；山西省有五个府，但有十三个分司；陕西省有八个府，但有二十四个分司。这样一来，管官的官多，管民的官少。县官被压得实在可怜，侍奉他上面的长官都来不及，哪有功夫亲民？这样一比较，还是汉代的地方政府设置合理。</p><p>明代的三司上面还有官，即总督和巡抚。这两个官职在明代还好，都是临时派到地方办事的，事情平定了就回到中央。但到了清代，总督、巡抚变成为永久的，地方行政就愈来愈坏了。</p><p>从历史源头上说来，汉时由刺史变成为牧，以及唐代之十道观察使，这些都是由监察官变成地方行政长官的。只有节度使才是 由军事长官变成行政长官，然而还是意在开边对外。明、清两代之总督、巡抚，则意在对内防乱。若非地方政治失败，又何来有此需要？这是中国政治史上的一大失败。本朝似乎也没逃出。</p><h3 id="明代考试制度">2.明代考试制度</h3><p>考试制度自唐历宋，还可说没有大变动。到明代，变动就大了。</p><p>唐宋两代的考试，由民间向地方政府呈报，送到中央，这些人就叫做“进士”，考上了叫做“进士及第”。到了明代，因为报考的人太多了，便分几次考。第一是府县试，录取了叫“秀才”；其次是省试，又叫乡试，中式者俗称“举人”；各省举人在送到中央，进行会试。中式后始为“进士”，也叫“进士及第”。进士及第后，要留在中央政府读书，满三年，再加一次考试，成绩好的就得进“翰林院”。明代风尚是是极其看重进士与翰林的，非进士、翰林就不能做大官。举人以下都没有做大官的份，沉在下面永不超升。这种制度，依然是重法不重人的。</p><p>不过这种制度也绝非没有好处。考取了进士，留在中央这几年，对政府一切实际政事都渐渐了解，政府给了他们一个好的出身，将来定做大官，这些人就可以安心努力，一边修学，一边获得政治知识。明、清两代，许多大学问家，大政治家，多半是进士、翰林出身。他们是政府故意栽培的人才，对政府而言，需要有一个储才之所。</p><p>再说八股文，这是明代考试制度里最坏的一件事。大家都知道八股文没意思，甚至有人会说这是专制政府故意用来愚民的。其实不尽然。从前唐代考试要考律诗，因为律诗限定字句，平平仄仄，要对得工整，易于评判。宋代考“经义”，仁义道德，大家一样都会说，谁好谁坏，很难辨。所以演变到了明代，又在经义中演变出一个一定的格式，违反这个格式就不录取。八股文像是变相的律诗，而这也不是一下子制定出来的，而是逐渐形成的。开始时的目的也是在录取真人才，然而人才终因此而消磨了。因此，一项制度，哪怕初心是好的，也有可能有流害。</p><h3 id="明代赋税制度">3.明代赋税制度</h3><p>不细讲。自明迄清，都有一种重要的册籍，名叫“黄册”和“鱼鳞册”，黄册登记户口，鱼鳞册登记田亩。但兼并之风仍存，因为任何一项制度的成立于推行，都需要与其他几项制度相配合，受其牵动和影响。拿土地制度和租税制度论，哪怕初心再好，实施到下面就会涉及到地方行政组织和效能，而这又会牵扯到各时代的社会形态。所以，我们应该意识到，一项新制度的成立与推行，其条件是如何的复杂，其考虑是该如何地周详。</p><h3 id="明代兵制">4.明代兵制</h3><p>明代的“卫所制度”就如唐代的府兵制，只是名称不同而已。每一个兵区，设在府里的叫“所”，连着两个府的叫“卫”。平时卫所给田自养，不需赋税。但为何偌大中国最后却被松花江外的一个小部落打败了呢？钱穆的观点大体是明代两三百年承平日久，疏于打仗，军备也破败不堪，难以应战。而且府兵制的缺陷在于军队分散到全国各地，一旦打大仗需要从全国各地方抽调，一加一小于二。大败后虽也找到了问题所在，但户部拿不出经费，经济落后拖了国防的后腿。突然出来一个满清，抵不住，也就不足为奇了。</p><p>​</p><p>​</p><h2 id="清代">清代</h2><h3 id="制度与法术">1.制度与法术</h3><p>制度出于公，是针对政治而言的；而法术出于私，只是事情或手段，不好说是政治。论汉代，西汉可说是制度，东汉则多半出于光武的私心。论唐代，确实可以说是在建立制度；而宋代，则有有许多只能说是一种法术；明代，有许多只能说它是一些事，不能说它是一些制。尤其是清代，可以说全无制度，它的所有制度，都是根据明代的制度，再加上满洲部落的私心，所以全只有私心。</p><h3 id="清代的部落政权">2.清代的部落政权</h3><p>这一部分的论述十分精彩。</p><p>钱穆从中西方的政治思想差异说起，西方讲政治，会讨论主权在哪里，教会？皇室？贵族？民众？中国则讲职责，只论政府该做什么事，尽了职没有，而并不讲主权在哪里。但若真要寻找中国的政治主权，则应该是“士人政权”。从汉到明都是如此，政府的大权都掌握在读书人手里，而读书人没有世袭特权，因此读书人“士”只是一种流品。在中国整部历史中，除了“士人政权”外，还有一种特殊的政权，钱穆称之为“部族特权”，即政权掌握在某一个部族手里。不论蒙古也好，满洲也好，都拿一个部族来控制政府。在这种政权下的一切措施都是带有私心的，而只能算是一种法术。明白了这一点，才可以来讲清代的制度。</p><h3 id="清代部族政权下的政府">3.清代部族政权下的政府</h3><p>（1）清代中央政府</p><p>清代政治与中国传统政治不同，因它背后有一批特别拥护皇帝的，即皇帝的同部族。这样的政权便是私政权，基础不稳固，因此它始终要袒护满洲人，才能控制牢固。</p><p>1）军机处</p><p>雍正时，内阁之外另添一“军机处”。后来许多事都不经内阁，直接由军机处发出。皇帝发出的最高命令叫“上谕”。正常走内阁流程的叫“明发上谕”，大都是一些不关紧要的事；而直接由皇帝军机处寄给受命令的人的，叫做“寄信上谕”。这种上谕，由军机处拟给皇帝看，皇帝看过后，封起来盖个印，这印一盖，谁也不能看，直接发给受命令的人。全国中外长官，都直接和皇帝发生关系，全国政治变成了秘密。这当然只能说是一种法术，而非制度。</p><p>而这种私心的政治，之所以做得下去，就是因为皇帝背后有满洲人撑腰。但凡专制独裁，其背后一定有一部分人强力支持，本朝也如此。</p><p>2）清代的六部尚书</p><p>在清代，六部尚书不能直接对下发命令，更不同的是，六部尚书、侍郎对皇帝皆得单独上奏。侍郎本是尚书的副官，对尚书负责，现在这样一来，尚书就管不着侍郎。而且，清代还要满汉分开，有一个中国尚书，一定还要有一个满洲尚书。侍郎同理。这些人都给皇帝上奏，皇帝还可以直接寄信上谕给某个人。这样一来，六部尚书还能做什么事？全国事情自然就更集中到皇帝手里了。</p><p>六部尚书、侍郎可以向皇帝单独讲话，除此之外，不论什么人都不许向皇帝讲话。地方官也只有总督、巡台、藩台（布政使）、臬台（按察使）可以直接向政府讲话其他地方官都不能专折言事。这比起明代，平民布衣可以向皇帝讲话，实在是差得太远了。</p><p>此外，清代不许民间有发言权。当时的府学、县学都设有明伦堂，清廷在每个明伦堂都置有石碑，这碑不是竖栽的而是横躺的，是为“卧碑”。卧碑上镌有几条禁令：</p><p>第一，生员不得言事；</p><p>第二，不得立盟结社；</p><p>第三，不得刊刻文字。</p><p>这恰恰是近代希望争取的“言论自由”“结社自由”“出版自由”。有名的金圣叹就因犯了卧碑禁令被杀头。这么看来，武侠小说里的“反清复明”倒有正当名义所在。</p><p>（2）清代地方政府</p><p>前面已经讲过，在明代布政使是地方最高行政长官，总督和巡抚非常设，有事派出，事平撤销。而到了清代，总督、巡抚成了常设。而总督和巡抚基本上都是满洲人。总之，清代不许地方官有真正的权柄。</p><h3 id="部族政权下的考试制度">4.部族政权下的考试制度</h3><p>若说考试是一种愚民政策，清代是当之无愧的。中国考试制度之用意，本在开放政权，选拔真才，分配于政府各部门。而清代的部族政权，绝无意于开放政权，之开放政权之一角落，让汉人们只能尝到一点甜头，以维护其统治。</p><h3 id="清代的统治政策">5.清代的统治政策</h3><p>大抵就是拉拢蒙古人来挟制汉人，一面压迫中国的知识分子，一面讨好下层民众，来分解中国社会的抵抗力。</p><p>总之清代在制度上，实在没几项是值得我们今天称道的。</p><h3 id="民众的反抗运动">6.民众的反抗运动</h3><p>底层民众不堪痛苦，民变四起。最有名的就是太平天国。但他们不懂政治，但从天王、东王、南王、西王、北王这些名号就能看出来。其集团里也没有读书人，这是满清政权存心分开知识分子和下层民众的成功。因此即使没有曾国藩、左宗棠，洪杨集团还是要失败的。不过，太平天国失败后，满清政权逐渐转移到中国人手中，军队变成了湘军和淮军（以前是八旗军）。逼出了满清政府以后的变法。</p><p>​</p><p>​</p><hr><h2 id="总结">总结</h2><p>第一，中央政府有逐步集权的倾向。如何在国家统一的基础上，不要太偏于中央集权，多注意地方政治的改进，是使得努力的一件事。</p><p>第二，中国历史上的传统政治，已造成社会各阶层逐渐趋于平等。除却元、清两代，都有废除特权的措施。封建贵族早已被废除，官吏不能世袭，政权普遍公开，考试符合标准谁都可以进入仕途。宛如一个平铺的社会。但这种平铺的社会也有毛病，就是平铺之后就没有力量了。说简单点就是没有了阶级矛盾，就没办法革命了。因为人都是平铺的，散漫的。钱穆讲，若讲平等，中国人最平等，若讲自由，中国人最自由。但平等里一个关键就是，谁来管政治？读了书都想去做官，容易导致政治臃肿。不过就今天来看，这个问题似乎被扭转过来了。以前的读书人追求的是修身齐家治国平天下，今天的读书人只剩下修身齐家了。</p><p>第三，皇室的权逐步升，政府的权逐步降。大抵是因为皇帝可以世袭，而官位不可以。</p><p>第四，中国的政治制度，相沿日久，呈繁密化的趋势。因为中国的制度偏重法制，即制度化，一个制度出了毛病，再订一个制度防制它，久而久之就变成了病上加病。制度愈繁密，人才愈束缚。所以，中国的政治制度给人一种“后不如前”的感觉。</p><p>最后，钱穆希望中国今后的制度可以做到，制度简化，人才自由发展。政治在才，不在法。以及注重历史，参考历史。</p><p>​</p><p>​</p><p><strong>最后简单做个小结</strong>：</p><p>如果有一个能穿越回古代，游历各朝的机会，这么安排比较合适：在汉唐做个平民，徭轻役薄，享盛世之乐，但请小心土地兼并；在宋代做文人，想些什么写什么，还没有杀头之祸；在明朝嘛，就勉为其难当个太监，体验下权倾朝野的感觉；在元清做个皇戚就行，毕竟天下都是你家的呗…</p><p>完。​​​​</p>]]></content>
      
      
      <categories>
          
          <category> 读书 </category>
          
          <category> 阅读笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 历史 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>位带操作</title>
      <link href="/2017/07/07/%E4%BD%8D%E5%B8%A6%E6%93%8D%E4%BD%9C/"/>
      <url>/2017/07/07/%E4%BD%8D%E5%B8%A6%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<p>一学期的嵌入式系统学下来，印象最深的就要属<strong>位带操作</strong>了，这是典型的用<u><strong>空间换效率</strong></u>的做法，是Cortex-M3内核的一大特色。在此写下一些心得，也算是给本学期嵌入式系统这门课画上一个句号。 <a id="more"></a> ## 什么是位带操作？ ## Cortex-M3在内存中划出了两片1MB大小的<strong>位带区</strong>，每一片位带区都有一片<strong>位带别名区</strong>与之对应。位带别名区的把每个比特膨胀成一个32位的字，这样，通过操作位带别名区中的4个字节的字，就能控制位带区的每一个比特。 <img src="https://raw.githubusercontent.com/C-Harlin/MarkDownPhotos/master/Bit%20band%20operation.png" alt="Alt 位带操作"> ## 为什么要有位带操作？ ## 通常，当我们要操作内存的某一位，即某一个比特时，都需要先把这个寄存器的值读到CPU中，然后经过移位、按位与或等等操作，最后再将新的值写回内存中去，完成修改。</p><p>这些操作其实没什么难度可言，就是写起来挺麻烦的，说白了就是dirty work……</p><p>因为懒是人类进步的动力嘛，所以我们希望能有办法避开这么复杂的操作，直接对任意比特进行操作。</p><p>于是，位带操作应运而生。</p><h2 id="位带操作的过程">位带操作的过程</h2><p>具体的过程我就不细讲了，书上有很详细的讲解。</p><p>大致思想就是，根据位带区中要操作的比特的地址（字节地址+比特位数），然后根据公式计算出对应的位带别名区中32位字的地址。这样，通过操作该字的第一个比特，就可以间接操作位带区中相应的比特位。</p><p>这样一来，省去了复杂的移位、与或等操作的代码，原来可能需要10行汇编语句才能完成的操作，现在只需要一两行就可以了，大大简化了原始操作。</p><h2 id="位带操作的优越性">位带操作的优越性</h2><p>最大的优点就是，<strong>位带操作属于原子操作</strong>！</p><p>原子操作就是不能被中途打断的操作。没办法再把这步操作分割成几步操作，所以叫做原子操作。通常，CPU在一个执行周期内是不允许被打断的，但需要注意的是，原子操作并不等同于一个执行周期可以执行完的操作。事实上，位带操作其实只是把那些复杂的操作打包成一步操作，例如读取比特位，看上去只需要一行汇编指令，但实际上呢，计算机还是会把这条汇编指令分成多条机器指令去执行。本质上，执行起来和没有位带操作时是一样的。<strong>所以位带操作并不会缩短执行时间</strong>。只是我们看起来比较舒服而已。</p><p>但是！因为是原子操作，所以不会被中断打断！而不采用位带操作时，就会有被中断打断的可能。我们当然希望需要执行的操作不会被莫名其妙的中断打断~因此这也相当于提高了效率。</p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 嵌入式 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
    
    
    <entry>
      <title>categories</title>
      <link href="/categories/index.html"/>
      <url>/categories/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>记录学习过程中的心得体会</title>
      <link href="/about/index.html"/>
      <url>/about/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>tags</title>
      <link href="/tags/index.html"/>
      <url>/tags/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
  
</search>
